#+MACRO: otb この設定値はトピック毎に上書き可能です( [[#topic-config][トピックレベルの設定]] を参照)。
* =broker.id=
| デフォルト |   |

各ブローカは非負整数の ID により一意に識別されます。
この ID はブローカの「名前」として使われ、
そのブローカが異なるホスト/ポートに移動した際にもコンシューマは混乱なく利用出来るようになります。

クラスタ内でユニークでありさえすれば任意の数値を設定できます。

* =log.dirs=
| デフォルト | =/tmp/kafka-logs= |

Kafka のデータが保存される1つ以上のディレクトリです。
複数指定する際はカンマで区切って指定します。
新しく作られた各パーティションは、
その時点で保持しているパーティションが最も少ないディレクトリに配置されます。

* =port=
| デフォルト | =9092= |

クライアントからの接続を受け付けるサーバのポート番号です。

* =zookeeper.connect=
| デフォルト | =null= |

ZooKeeperとの接続情報を =hostname:port= という形式で文字列で指定します。
=hostname= 、 =port= はそれぞれ ZooKeeper クラスタに属するノードのホスト名とポート番号です。
=hostname1:port1,hostname2:port2,hostname3:port3= のように複数のホストを指定することで、
ホストダウン時に他のZooKeeperノードへ接続出来るように出来ます。

ZooKeeper では "chroot" パスを追加することも出来、
これによってクラスタ内の全ての Kafka データが特定のパス以下に配置されるように設定出来ます。
こうすることで、異なる Kafka クラスタや他のアプリケーションを、同じ ZooKeeper クラスタ上に構築出来ます。
具体的には、 =hostname1:port1,hostname2:port2,hostname3:port3/chroot/path= のように指定することで、
全 Kafka クラスタのデータが =/chroot/path= 以下に配置されるように出来ます。

#+begin_note
chroot を指定する場合、ブローカを起動する前にパスを作っておく必要があります。
また、全コンシューマが同じ接続情報文字列を利用するようにしなければなりません。
#+end_note

* =message.max.bytes=
:PROPERTIES:
:CUSTOM_ID: borker-message-max-bytes
:END:

| デフォルト | 1000000 |

サーバが受け取るメッセージの最大サイズです。
このプロパティは [[#consumer-fetch-message-max-bytes][コンシューマが利用する最大取得サイズ設定]] と同調して設定するよう注意しましょう。
さもなければ、乱暴なプロデューサがコンシューマが扱えない程のサイズのメッセージを
パブリッシュすることが出来るようになってしまいます。


* =num.network.threads=
| デフォルト | 3 |

サーバがネットワークリクエストを処理するのに使うネットワークスレッドの数です。
恐らく変更する必要はありません。

* =num.io.threads=
| デフォルト | 8 |

サーバがリクエストを処理するために使う I/O スレッドの数です。
少なくとも利用するディスク数分は用意するべきです。

* =background.threads=
| デフォルト | 10 |

ファイル削除のような様々なバックグラウンド処理を行なう為に使われるスレッドの数です。
変更する必要はないでしょう。

* =queued.max.requests=
| デフォルト | 500 |

I/O スレッドが処理する為にキューに詰まれる最大リクエスト数で、
この数までキューに詰まれると、ネットワークスレッドは新規リクエストを読むのを止めます。

* =host.name=
| デフォルト | null |

ブローカのホスト名です。
この値が設定されていれば、そのアドレスにだけバインドします。
設定されていなければ、全インタフェースにバインドします。
この情報は ZooKeeper にパブリッシュされクライアントから利用されます。

* =advertised.host.name=
| デフォルト | null |

この値が設定されていれば、 プロデューサやコンシューマ、そして他のブローカが接続するホスト名として利用されます。

[fn:: (訳注) 関連 issue [[https://issues.apache.org/jira/browse/KAFKA-1092][KAFKA-1092]]]

* =advertised.port=
| デフォルト | null |

プロデューサやコンシューマ、そして他のブローカが接続するポート番号です。
サーバがバインドするポートと異なる場合のみ必要な設定です。

* =socket.send.buffer.bytes=
| デフォルト | 100 * 1024 |

ソケット接続時にサーバが利用する =SO_SNDBUFF= バッファの値です。

* =socket.receive.buffer.bytes=
| デフォルト | 100 * 1024 |

ソケット接続時にサーバが利用する =SO_RCVBUFF= バッファの値です。

* =socket.request.max.bytes=
| デフォルト | 100 * 1024 * 1024 |

サーバが許容する最大リクエストサイズです。
メモリ不足に陥らないよう、 Java ヒープサイズよりも小さい値に設定すべきです。

* =num.partitions=
| デフォルト | 1 |

トピック作成時に指定されなかった場合のデフォルトパーティション数です。


* =log.segment.bytes=
| デフォルト | 1024 * 1024 * 1024 |

トピックパーティションのログは、セグメントファイルのディレクトリとして保存されています。
1セグメントのファイルサイズがこの値に達すると、新しいセグメントファイルが作成されます。
[fn:: (訳注) =log_dirs= に、 =<トピック名>-<パーティション番号>/000...000.log= の様に保存されています。 ]
{{{otb}}}

* =log.roll.{ms,hours}=
| デフォルト | 24 * 7 hours |

セグメントファイルサイズが =log.segment.bytes= に到達していない場合でも、
この設定値の時間が経過した場合に強制的に新たなログセグメントを作成するよう設定します。
{{{otb}}}

* =log.cleanup.policy=
| デフォルト | delete |

=delete= または =compact= を設定出来ます。
ログセグメントがサイズや時間の上限に達した際に、
=delete= の場合は削除され、 =compact= の場合は [[http://kafka.apache.org/documentation.html#compaction][ログコンパクション]] が行なわれます。
{{{otb}}}

* =log.retention.{ms,minutes,hours}=
| デフォルト | 7 days |

ログセグメントを削除するまでの時間、つまりトピックのデフォルト保持期間です。

#+begin_note
=log.retention.minutes= と =log.retention.bytes= が両方セットされていた場合、
いずれかの上限に達した時点でクリーンアップを行ないます。
#+end_note

{{{otb}}}

* =log.retention.bytes=
| デフォルト | -1 |

各トピックパーティションログの総サイズ制限です。
これはパーティション毎の制限なので、トピックが必要とするトータルのデータ容量は、これにパーティション数を掛けた値になります。

#+begin_note
=log.retention.minutes= と =log.retention.bytes= が両方セットされていた場合、
いずれかの上限に達した時点でクリーンアップを行ないます。
#+end_note

{{{otb}}}

* =log.retention.check.interval.ms=
| デフォルト | 5 minutes |

ログの保持ポリシーと照らし合わせて、削除対象となるログセグメントがあるかどうかを確認する間隔です。

* =log.cleaner.enable=
| デフォルト | false |

ログコンパクションを実行するためには、この設定は必ず =true= にしなければなりません。

* =log.cleaner.threads=
| デフォルト | 1 |

ログコンパクション実行時のログクリーニングに使われるスレッド数です。

* =log.cleaner.io.max.bytes.per.second=
| デフォルト | Double.MaxValue |

ログクリーナがログコンパクション実行時に発生する I/O の最大総サイズです。
この制限を設けることで、クリーナが運用中のサービスに影響を与えることを避けることが出来ます。

* =log.cleaner.dedupe.buffer.size=
| デフォルト | 500*1024*1024 |

ログクリーナがクリーニング中にインデクシングとログの重複除去のために使用するバッファサイズです。
十分なメモリがあるならば、より大きな値の方が望ましいです。

* =log.cleaner.io.buffer.size=
| デフォルト | 512*1024 |

ログクリーニング中に使用される I/O チャンクのサイズです。
恐らく変更する必要はないでしょう。

* =log.cleaner.io.buffer.load.factor=
| デフォルト | 0.9 |

ログクリーニング中に使用されるハッシュテーブルの load factor です。
恐らく変更する必要はないでしょう。

* =log.cleaner.backoff.ms=
| デフォルト | 15000 |

クリーニングが必要なログが無いか確認する間隔です。

* =log.cleaner.min.cleanable.ratio=
| デフォルト | 0.5 |

[[http://kafka.apache.org/documentation.html#compaction][ログコンパクション]] が有効なときの、ログコンパクタがログをクリーンする頻度を設定します。
デフォルトでは50%以上のログがコンパクションされていた場合はクリーニングを行ないません。
この比率はログの重複により無駄に使用される最大スペースを設定します
(50%だと、多くて50%のログが重複している可能性がある、ということです)。
より高い比率に設定すれば、少ない回数で、より効率的なクリーニングが行われることになりますが、
それは同時にログが無駄に使用するスペースがより多くなるということにもなります。
{{{otb}}}

* =log.cleaner.delete.retention.ms=
| デフォルト | 1 day |

[[http://kafka.apache.org/documentation.html#compaction][ログコンパクション]] されたトピックの削除トゥームストーンマーカを保持する期間です。
最終段階の有効なスナップショットを確実に得る為にオフセット 0 から読み込みを開始する場合、
コンシューマはこの期間内に読み込みを完了させる必要があります。
{{{otb}}}

* =log.index.size.max.bytes=
| デフォルト | 10 * 1024 * 1024 |

各ログセグメントのオフセットインデックスが使用する容量の最大バイト数です。
ここで設定した容量のスパースファイルを事前に確保して、
新たなログセグメント作成のタイミングで実容量まで縮める、という動作をする点に注意してください。
インデックスがいっぱいになってしまった場合は、
=log.segment.bytes= を超過していない場合でも新たなログセグメントを作成します。
{{{otb}}}

* =log.index.interval.bytes=
| デフォルト | 4096 |

オフセットインデックスにエントリを追加するバイト間隔です。
取得リクエストを実行する際、サーバは取得を開始、あるいは終了するために、
正しいログ内の位置を見つけるため、ここで設定したバイト数まで線形走査する必要があります。
そのためこの値を大きくすればする程インデックスファイルは大きくなり
(そしてもう少しだけメモリを使用するようになり)ますが、走査回数は少なくなります。
[fn:: (訳注) 何言ってんのかよく分かんない]
ただ、サーバはログ追加毎に2つ以上インデックスエントリを追加することは決してありません
(たとえ =log.index.interval= を上回るメッセージが追加されたとしても)。
普通はこの値をいじる必要は無いでしょう。

* =log.flush.interval.messages=
| デフォルト | Long.MaxValue |

ここで設定された数までメッセージをログパーティションに書き込んだら、強制的にログを fsync します。
この値を小さくすれば頻繁にディスクにデータを同期するようになりますが、パフォーマンスに多大な影響を与えます。
耐久性を得るためには、単一サーバの fsync に依存するよりもレプリケーションを利用することを通常は推奨しますが、
さらなる確実性を求める場合はこの設定を利用することも出来ます。

* =log.flush.scheduler.interval.ms=
| デフォルト | Long.MaxValue |
ログフラッシャがディスクにフラッシュするのに適したログがあるかをチェックする頻度をミリ秒で設定します.

* =log.flush.interval.ms=
| デフォルト | Long.MaxValue |

ログの fsync がコールされるまでの最大時間です。

=log.flush.interval.messages= と合わせて設定された場合は、
どちらかの条件を満たした時点でログがフラッシュされます。

* =log.delete.delay.ms=
| デフォルト | 60000 |

メモリ上のセグメントインデックスから除去された後にログファイルを保持しておく期間です。
この期間はロックせずとも進行中の読み込みを中断することなく完了することが出来ます。
[fn:: (訳注) 何言ってんのかよく分かんない]
通常はこの値を変更する必要は無いでしょう。

* =log.flush.offset.checkpoint.interval.ms=
| デフォルト | 60000 |

リカバリのためにログの最終フラッシュのチェックポイントをセットする頻度です。
これは変更すべきではありません。

* =log.segment.delete.delay.ms=
| デフォルト | 60000 |

ファイルシステムからログセグメントファイルを削除するまでの時間です。

* =auto.create.topics.enable=
| デフォルト | true |

サーバに自動でトピックを作成可能にします。
この設定が有効な場合、存在しないトピックを作成、あるいはそのメタデータを取得しようとした際に、
デフォルトのレプリケーションファクタとパーティション数で自動的にトピックが作成されます。

* =controller.socket.timeout.ms=
| デフォルト | 30000 |

レプリカに対するパーティション管理コントローラのソケットタイムアウトです。

* =controller.message.queue.size=
| デフォルト | Int.MaxValue |

コントローラからブローカへの接続チャネル( =controller-to-broker-channels= )のバッファサイズです。

* =default.replication.factor=
| デフォルト | 1 |
自動作成されたトピックのデフォルトレプリケーションファクタです。

* =replica.lag.time.max.ms=
| デフォルト | 10000 |

フォロワがここで設定した時間内に取得リクエストを送信しなかった場合、
リーダはそのフォロワを ISR (in-sync replicas) から除去し、死んだものとして扱います。

* =replica.lag.max.messages=
| デフォルト | 4000 |

ここで設定したメッセージ数よりレプリケーションが遅れた場合、
リーダはそのフォロワを ISR (in-sync replicas) から除去し、死んだものとして扱います。

* =replica.socket.timeout.ms=
| デフォルト | 30 * 1000 |

データ複製の為のリーダへのネットワークリクエストのソケットタイムアウトです。

* =replica.socket.receive.buffer.bytes=
| デフォルト | 64 * 1024 |

データ複製の為のリーダへのネットワークリクエストのソケット受信バッファです。

* =replica.fetch.max.bytes=
| デフォルト | 1024 * 1024 |

レプリカがリーダへ送信する取得リクエスト時の、
各パーティションについて取得を試行するメッセージのバイト数です。

* =replica.fetch.wait.max.ms=
| デフォルト | 500 |

レプリカがリーダへ送信する取得リクエスト時の、リーダへデータが到達するまでの待機時間です。

* =replica.fetch.min.bytes=
| デフォルト | 1 |

レプリカがリーダへ送信する取得リクエストに対する各取得レスポンスが想定する最小バイトです。
この設定に満たない場合は、 =replica.fetch.wait.max.ms= まで待機します。

* =num.replica.fetchers=
| デフォルト | 1 |

リーダからメッセージを複製するのに使うスレッド数です。
この設定値を増やすとフォロワブローカの I/O 並列処理数が増加します。

* =replica.high.watermark.checkpoint.interval.ms=
| デフォルト | 5000 |

各レプリカがリカバリ処理の為に自身のハイウォータマークを記録する頻度です。

* =fetch.purgatory.purge.interval.requests=
| デフォルト | 1000 |

取得リクエストパーガトリの [fn:purgatory: (訳注) [[https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=34839465][Request Purgatory (0.8) - Apache Kafka - Apache Software Foundation]] ]
解放間隔(リクエスト数)です。

* =producer.purgatory.purge.interval.requests=
| デフォルト | 1000 |

プロデューサリクエストパーガトリ [fn:purgatory] の解放間隔(リクエスト数)です。

* =zookeeper.session.timeout.ms=
| デフォルト | 6000 |

ZooKeeper のセッションタイムアウトです。
ZooKeeperへのハートビートがこの期間失敗すると、そのサーバは死んだものとされます。
この値をあまりにも小さくしてしまうと、サーバが死んだと誤検知されてしまうかもしれませんし、
かといって大きくし過ぎると、本当に死んだサーバを認識するのに時間がかかるようになってしまいます。

* =zookeeper.connection.timeout.ms=
| デフォルト | 6000 |

クライアントが ZooKeeper との接続を確立するまでの最大待機時間です。

* =zookeeper.sync.time.ms=
| デフォルト | 2000 |

ZooKeeper フォロワがリーダからどのくらい遅れ得るかです。

* =controlled.shutdown.enable=
| デフォルト | true |

ブローカの制御シャットダウンを有効にします。
この設定が有効な場合、そのブローカはシャットダウン前に自身のリーダ権を全て他のブローカに移動させます。
これによりシャットダウン中のサービス不能期間を減らすことが出来ます。

* =controlled.shutdown.max.retries=
| デフォルト | 3 |

制御シャットダウンが成功するまでのリトライ回数です。
この回数を超えて失敗すると、強制シャットダウンされます。

* =controlled.shutdown.retry.backoff.ms=
| デフォルト | 5000 |

シャットダウンのリトライ時のバックオフ時間です。

* =auto.leader.rebalance.enable=
| デフォルト | true |

この設定が有効な場合、コントローラは自動的にブローカ間でパーティションのリーダ権のバランシングを試みます。
バランシングは、定期的にリーダ権を各パーティションの「優先」レプリカに返却することによって行なわれます(「優先」レプリカが存在する場合)。

* =leader.imbalance.per.broker.percentage=
| デフォルト | 10 |

リーダのブローカ毎の偏りのパーセンテージです。
コントローラはブローカ毎にこの割合を超えた場合にリーダ権のリバランスを行います。

* =leader.imbalance.check.interval.seconds=
| デフォルト | 300 |

リーダの偏りを検査する頻度です。

* =offset.metadata.max.bytes=
| デフォルト | 4096 |

クライアントが自身のオフセットを記録するためのメタデータの最大容量です。

* =max.connections.per.ip=
| デフォルト | Int.MaxValue |

ブローカが IP 毎に許可する接続数の最大値です。

* =max.connections.per.ip.overrides=
| デフォルト |   |

IP またはホスト名を指定して、デフォルトの最大接続数を上書き出来ます。

* =connections.max.idle.ms=
| デフォルト | 600000 |

アイドルコネクションタイムアウト、つまり、
サーバソケットプロセッサスレッドがこの値以上アイドル状態だった場合に接続を閉じます。

* =log.roll.jitter.{ms,hours}=
| デフォルト | 0 |

=logRollTimeMillis= から減じられる最大ジッタです。

* =num.recovery.threads.per.data.dir=
| デフォルト | 1 |

データディレクトリ毎に起動時のログリカバリやシャットダウン時のフラッシュに使用されるスレッド数です。

* =unclean.leader.election.enable=
| デフォルト | true |

最終手段として ISR 以外のレプリカをリーダとして選択することを許可するかどうかを示します。
これによりデータがロストする可能性があります。

* =delete.topic.enable=
| デフォルト | false |

トピックを削除出来るようにします。

* =offsets.topic.num.partitions=
| デフォルト | 50 |

オフセットコミットトピックのパーティション数です。
デプロイ後にこの値を変えることは現在サポートされていないため、
プロダクション環境ではより大きい数値(例えば 100-200)に設定することを推奨します。

* =offsets.topic.retention.minutes=
| デフォルト | 1440 |

この値よりも古いオフセットは削除対象としてマークされます。
ログクリーナがオフセットトピックのコンパクションを実行した際に、実際に削除されます。

* =offsets.retention.check.interval.ms=
| デフォルト | 600000 |

オフセットマネージャが古くなったオフセットを検査する頻度です。

* =offsets.topic.replication.factor=
| デフォルト | 3 |

オフセットコミットトピックのレプリケーションファクタです。
高可用性を保証するにはこの値をより高い値(3や4等)に設定することを推奨します。
レプリケーションファクタよりも少ないブローカしかいな場合にオフセットトピックが作成された場合は、
この設定よりも少ないレプリカしか作られません。

* =offsets.topic.segment.bytes=
| デフォルト | 104857600 |

オフセットトピックのセグメントサイズです。
オフセットトピックはコンパクションされたトピックを使う為、
ログコンパクションとロードを高速に行ない易くするためには
この設定値は比較的小さな値にしておくべきです。

* =offsets.load.buffer.size=
| デフォルト | 5242880 |

ブローカがあるコンシューマグループのオフセットマネージャになった時に
(つまり、 オフセットトピックのリーダになった時に)、オフセットのロードが行なわれます。
オフセットマネージャのキャッシュにオフセットをロードする際に、
ここで設定したバッチサイズ(バイト数指定)を参照してオフセットセグメントからの読み込みを行ないます。

* =offsets.commit.required.acks=
| デフォルト | -1 |

オフセットコミットが受け入れられる為に必要な Ack 数です。
プロデューサの Ack 設定と似たようなものです。
通常はデフォルト値から変更すべきではありません。

* =offsets.commit.timeout.ms=
| デフォルト | 5000 |

このタイムアウト分か、必要なレプリカがオフセットコミットを受信するまでオフセットコミットは遅延されます。
プロデューサのリクエストタイムアウトと似たようなものです。
