<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Apache Kafka</title>
<!-- 2015-05-18 月 22:02 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="yewton" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="../org-html-themes/styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="../org-html-themes/styles/readtheorg/css/readtheorg.css"/>
<script src="js/jquery.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<link href="css/src-block-theme.css" rel="stylesheet">
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Apache Kafka</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. はじめよう</a>
<ul>
<li><a href="#sec-1-1">1.1. 導入</a></li>
<li><a href="#sec-1-2">1.2. ユースケース</a></li>
<li><a href="#sec-1-3">1.3. クイックスタート</a></li>
<li><a href="#sec-1-4">1.4. エコシステム</a></li>
<li><a href="#sec-1-5">1.5. 以前のバージョンからのアップグレード</a></li>
</ul>
</li>
<li><a href="#sec-2">2. API</a>
<ul>
<li><a href="#sec-2-1">2.1. プロデューサ API</a></li>
<li><a href="#sec-2-2">2.2. ハイレベルコンシューマ API</a></li>
<li><a href="#sec-2-3">2.3. シンプルコンシューマ API</a></li>
<li><a href="#sec-2-4">2.4. Kafka Hadoop コンシューマ API</a></li>
</ul>
</li>
<li><a href="#sec-3">3. 設定</a>
<ul>
<li><a href="#sec-3-1">3.1. ブローカ設定</a></li>
<li><a href="#sec-3-2">3.2. Consumer Configs</a></li>
<li><a href="#sec-3-3">3.3. Producer Configs</a></li>
<li><a href="#sec-3-4">3.4. New Producer Configs</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> はじめよう</h2>
<div class="outline-text-2" id="text-1">
</div>

<div id="outline-container-sec-1-1" class="outline-3">
<h3 id="sec-1-1"><span class="section-number-3">1.1</span> 導入</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Kafka は分散し、分割され、複製されるコミットログサービスです。
メッセージングシステムの機能を提供しますが、その設計は独特なものです。
</p>

<p>
つまり、どういうことでしょう？
</p>

<p>
はじめに、基本的なメッセージングの用語を確認しておきましょう:
</p>

<ul class="org-ul">
<li>Kafka は <i>トピック</i> と呼ばれるカテゴリ毎にメッセージのフィードを保持しています
</li>
<li>Kafka のトピックに対してメッセージを発行するプロセスを <i>プロデューサ</i> と呼びます
</li>
<li>複数のトピックを購読し、発行されたメッセージのフィードを処理するプロセスを <i>コンシューマ</i> と呼びます
</li>
<li>Kafka はひとつ以上の <i>ブローカ</i> と呼ばれるサーバで構成されるクラスタとして動作します
</li>
</ul>

<p>
すなわち以下の図のように、高レベルな視点ではプロデューサ群がネットワーク上で Kafka クラスタにメッセージを送信し、
そのメッセージを順次コンシューマ群に向けて提供する、というように動作します:
</p>


<div class="figure">
<p><img src="images/producer_consumer.png" alt="producer_consumer.png" />
</p>
</div>

<p>
クライアントとサーバ間の通信はシンプルかつ高性能で、言語に依存しない <a href="https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol">TCP protocol</a> で行なわれます。
提供されるのは Java の Kafka クライアントですが、 <a href="https://cwiki.apache.org/confluence/display/KAFKA/Clients">多くの言語で</a> 利用することが出来ます。
</p>
</div>

<div id="outline-container-sec-1-1-1" class="outline-4">
<h4 id="sec-1-1-1">トピックとログ</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
まず最初に、 Kafka が提供する高レベルな抽象概念である「トピック」について見ていきましょう。
</p>

<p>
トピックはカテゴリ、あるいはフィードの名前であり、メッセージはトピックに対して発行されます。
以下の図のように、Kafka クラスタはトピックごとにログを分割して保持しています:
</p>


<div class="figure">
<p><img src="images/log_anatomy.png" alt="log_anatomy.png" />
</p>
</div>

<p>
各パーティションは不変で順序があるメッセージ列で、メッセージは断続的に追記されます。
このメッセージ列を「コミットログ」と呼びます。
メッセージには、格納されたパーティションごとに「オフセット」と呼ばれるユニークな通し番号が付与されます。
このオフセットにより、パーティション内のメッセージを一意に特定することができます。
</p>

<p>
Kafka クラスタは、コンシュームされたかどうかに拘わらず、発行されたすべてのメッセージを保存しています。
保持する期間は設定で変更可能です。
例えばログ保存期間が2日間に設定されている場合、あるメッセージが発行されてから2日間はコンシューム可能ですが、
それ以降は容量確保のために破棄されます。
Kafkaの性能はデータサイズに関しては実質定数のため、大量のデータを保存することは問題ありません。
</p>

<p>
実は、コンシューマ毎に保存されているメタデータというのは、ログ内のコンシューマの位置情報だけです。
これは「オフセット」と呼ばれます。
オフセットはコンシューマにより制御されます————通常はメッセージを読み進めるのに応じて順番にオフセットを進めますが、
オフセットの制御は実際のところコンシューマが行なうため、任意の順序でコンシュームすることが出来ます。
例えば、コンシューマは昔のオフセットにリセットして再処理を行なうことが出来ます。
</p>

<p>
以上の機能の組合せにより、Kafkaのコンシューマはとても安価であると言えます————コンシューマはクラスタへの参加・離脱を、
そのクラスタや、クラスタに所属する他のコンシューマに大きな影響を与えることなく行なうことができる、ということです。
例えば、任意のトピックについて、付属のコマンドラインツールで「tail」操作を行なうことが出来ますが、
これは既存のコンシューマのコンシューム状況を変えることなく行なうことが可能です。
</p>

<p>
パーティションは様々な目的で提供されています。
第一に、ログを一台のサーバに収まりきらないサイズにまでスケールすることを可能にする目的です。
個々のパーティションについては、それを格納するサーバに収まるように調整する必要がありますが、
トピックは複数のパーティションに分割されるため、トピックのデータ量は無制限です。
第二に、パーティションは並行処理の単位としても利用されます————詳細は後述します。
</p>
</div>
</div>

<div id="outline-container-sec-1-1-2" class="outline-4">
<h4 id="sec-1-1-2">分散</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
ログのパーティションは Kafka クラスタ内のサーバ上で分散して保持されており、
各サーバはパーティションを共有するためのデータとリクエストを処理します。
耐障害性のために、各パーティションを複数のサーバに複製することも出来ます。
複製するサーバ数は設定で変更可能です。
</p>

<p>
各パーティションは「リーダ」となる一つのサーバと、0以上の「フォロワ」サーバを持ちます。
リーダは担当のパーティションへの全ての読み書きリクエストを処理します。
対してフォロワは、リーダの複製を受動的に行ないます。
リーダに障害が発生した場合、フォロワのどれかが自動的に新たなリーダとなります。
各サーバはクラスタ内の負荷が均等になるように、自身のパーティションのうちいくつかのリーダとなり、
その他のパーティションのフォロワともなります。
</p>
</div>
</div>

<div id="outline-container-sec-1-1-3" class="outline-4">
<h4 id="sec-1-1-3">プロデューサ</h4>
<div class="outline-text-4" id="text-1-1-3">
<p>
プロデューサは自身の選択したトピックに対してデータを発行します。
プロデューサはどのメッセージをトピック内のどのパーティションに割り当てるかを選択する責務があります。
これは負荷分散のためにラウンドロビン方式で選択することも出来ますし、
何らかの意味的な分割関数を利用することも出来ます(例えばメッセージの特定のキーを元に分割するなど)。
パーティションの利用に関する詳細は後述します。
</p>
</div>
</div>

<div id="outline-container-sec-1-1-4" class="outline-4">
<h4 id="sec-1-1-4">コンシューマ</h4>
<div class="outline-text-4" id="text-1-1-4">
<p>
伝統的なメッセージングのモデルは <a href="http://en.wikipedia.org/wiki/Message_queue">キューイング</a> と <a href="http://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">出版・購読型</a> の二つです。
キューを用いる方法では、コンシューマプールがひとつのサーバからメッセージを取得することができ、
各メッセージはコンシューマのいずれか一つに渡ります。
一方の出版・購読型モデルでは、メッセージは全てのコンシューマにブロードキャストされます。
Kafka はその両方を一般化するコンシューマの抽象概念を提供しています。
それが「コンシューマグループ」です。
</p>

<p>
コンシューマは自分自身にコンシューマグループ名をラベル付けしており、
トピックに発行される各メッセージは、そのトピックを購読している各コンシューマグループそれぞれの、
ある一つのコンシューマインスタンスに対して屆けられます。
コンシューマインスタンスは異なるプロセス、あるいは異なるサーバ上で稼動させることが出来ます。
</p>

<p>
全てのコンシューマインスタンスが同一のコンシューマグループに属しているならば、
コンシューマ上で負荷分散される伝統的なキューイングモデルのように動きます。
</p>

<p>
全てのコンシューマインスタンスがそれぞれ異なるコンシューマグループに属しているならば、
出版・購読型モデルのように動き、メッセージは全てのコンシューマにブロードキャストされることになります。
</p>

<p>
しかしより一般には、トピックは「論理的な購読者」を表す少数のコンシューマグループを持つことになるでしょう。
各グループはスケーラビリティと耐障害性のため、複数のコンシューマインスタンスで構成されます。
これは購読者が単一のプロセスではなく、コンシューマのクラスタとなっている出版・購読型モデルそのものです。
</p>


<div class="figure">
<p><img src="images/consumer-groups.png" alt="consumer-groups.png" />
</p>
<p><span class="figure-number">Figure 3:</span> 4つのパーティション(P0-P3)をホスティングする2つのサーバで構成されるKafka クラスタ、及び2つのコンシューマグループ。グループAは2つ、Bは4つのインスタンスを持っている。</p>
</div>

<p>
また、Kafkaは伝統的なメッセージングシステムと比べてより強力な順序保証を提供しています。
</p>

<p>
伝統的なキューはメッセージを順番にサーバ上に保存しています。
複数のコンシューマがそのキューからコンシュームした場合、
サーバは保存されている順番にメッセージを取り出すでしょう。
しかし、サーバがメッセージを順番に取り出したところで、
コンシューマへのメッセージの配信は非同期に行われるため、
異なるコンシューマ間のメッセージ到達順序は狂う可能性があります。
つまり、コンシューマを並列に動かすような状況では、メッセージの順序は失われる、ということです。
メッセージングシステムはしばしば「排他的コンシューマ」という概念を利用して問題を回避しようとします。
ひとつのキューに対してただひとつプロセスのみコンシューム可能とする、というものです。
しかしこれは当然、並列処理は出来ません。
</p>

<p>
Kafka はもっと上手いことやっています。
トピック内の並列性(これはつまり、パーティションのことです)という概念を利用することで、
Kafkaはコンシューマプロセスプール上の順序保証と負荷分散の両方を提供することが出来ます。
これは、各パーティションがグループ内のただ一つのコンシューマにのみコンシュームされるように、
トピック内のパーティションをコンシューマグループ内のコンシューマに割り当てることで実現されています。
これによって、パーティションを読むのはある特定コンシューマだけであることと、順序通りコンシュームすることが保証されます。
多くのパーティションがある為、これでもコンシューマインスタンス間の負荷は分散します。
ただし、パーティション数以上のコンシューマインスタンスは存在し得ないことに注意してください。
</p>

<p>
Kafka はトピック内のパーティションの <i>中の</i> メッセージ順序しか保証しません。
異なるパーティション間の順序は保証されません。
ほとんどのアプリケーションは、パーティション毎の順序とキー毎の分割機能との組み合わせで十分でしょう。
もし、全メッセージの順序が必要な場合は、パーティションひとつだけからなるトピックを使うことで実現出来ますが、
この場合コンシューマプロセスもただ一つのみになります。
</p>
</div>
</div>

<div id="outline-container-sec-1-1-5" class="outline-4">
<h4 id="sec-1-1-5">保証</h4>
<div class="outline-text-4" id="text-1-1-5">
<p>
高レベルな視点では Kafka は以下の保証を提供します:
</p>

<ul class="org-ul">
<li>プロデューサから特定のトピックパーティションへと送られたメッセージは、送られた順に追記されます。
つまり、メッセージ <code>M1</code> と <code>M2</code> が同じプロデューサから送られ、かつ <code>M1</code> が最初に送られていた場合、
<code>M1</code> は <code>M2</code> よりも小さいオフセットを持ち、 <code>M2</code> よりも先にログに現れます。
</li>
<li>コンシューマインスタンスはログに保存されている順番にメッセージを読みます。
</li>
<li>レプリケーションファクタ <code>N</code> に設定されたトピックは、 <code>N-1</code> 個までのサーバ障害については、
メッセージのロスト無く稼動することが出来ます。
</li>
</ul>

<p>
これらの保証のより詳細については、本ドキュメントの設計セクションで述べられています。
</p>
</div>
</div>
</div>

<div id="outline-container-sec-1-2" class="outline-3">
<h3 id="sec-1-2"><span class="section-number-3">1.2</span> ユースケース</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Apache Kafka のユースケースをいくつか紹介します。
これらの分野についての数多くの取り組みの概要が <a href="http://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying">このブログ記事</a> にまとめられています。
</p>
</div>

<div id="outline-container-sec-1-2-1" class="outline-4">
<h4 id="sec-1-2-1">メッセージング</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
Kafka は伝統的なメッセージブローカの代替として使うことが出来ます。
メッセージブローカを利用する理由は様々です————
データ生成と処理を疎結合にする為、未処理のメッセージをバッファするため、等。
ほとんどのメッセージングシステムと比較して、
Kafka はより良いスループット、組込みのパーティショニング、複製、耐障害性を備えており、
大規模メッセージ処理アプリケーションの良いソリューションとなります。
</p>

<p>
経験上、メッセージングは比較的低いスループットで、しかしエンドツーエンドの低いレイテンシを要求し、
また、Kafka が提供する強い堅牢性に関する保証に依存するという場合が多いです。
</p>

<p>
このドメインでは、 <a href="http://activemq.apache.org/">ActiveMQ</a> や <a href="http://activemq.apache.org/">ActiveMQ</a> のような伝統的なメッセージングシステムと Kafka を比較することが出来ます。
</p>
</div>
</div>

<div id="outline-container-sec-1-2-2" class="outline-4">
<h4 id="sec-1-2-2">Web サイトのアクティビティトラッキング</h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
ユーザ動向追跡パイプラインを、リアルタイムな Pub-Sub フィードの集合として再構築する、というのが Kafka の元々のユースケースでした。
つまり、サイトアクティビティ(ページビュー、検索等のユーザが取り得る行動)はアクティビティの種別毎にトピック分けされて、
中央に集められるということです。
これらのフィードは幅広いユースケースで利用することが出来ます。
リアルタイム処理やリアルタイム監視のために使われたり、
オフラインでの処理やレポートで利用するために Hadoop やオフラインのデータウェアハウジングシステムへ保存するために使われたりします。
</p>

<p>
アクティビティトラッキングは各ユーザのページビューごとに大量のアクティビティメッセージが生成されるため、
しばしば超大容量のログを扱うことになります。
</p>
</div>
</div>

<div id="outline-container-sec-1-2-3" class="outline-4">
<h4 id="sec-1-2-3">メトリクス</h4>
<div class="outline-text-4" id="text-1-2-3">
<p>
Kafka は運用監視データとしても使われることがあります。
この場合は、運用データの中央フィードを生成するため、分散したアプリケーションの統計を集約するのに用いられます。
</p>
</div>
</div>

<div id="outline-container-sec-1-2-4" class="outline-4">
<h4 id="sec-1-2-4">ログ集約</h4>
<div class="outline-text-4" id="text-1-2-4">
<p>
ログ集約ソリューションの代替として Kafka を利用する場合も多いです。
典型的なログ集約では、物理ログファイルをサーバから収集し、
ファイルサーバや HDFS のような中央ストレージに配置して処理されます。
Kafka はファイルの詳細について抽象化し、
また、ログやイベントデータをメッセージストリームとしてきれいに抽象化しています。
これにより、より低レイテンシで処理でき、また複数のデータソースや分散データ処理への対応が容易になります。
Scribe や Flume といったログ集約システムと比較して、
Kafka や同等のパフォーマンスと、複製によるより強い堅牢性保証、
及びエンドツーエンドのより低いレイテンシを提供します。
</p>
</div>
</div>


<div id="outline-container-sec-1-2-5" class="outline-4">
<h4 id="sec-1-2-5">ストリーム処理</h4>
<div class="outline-text-4" id="text-1-2-5">
<p>
多くのユーザは段階的なデータ処理をすることになります。
データは生データのトピックからコンシュームされ、集約され、肉付けされ、
あるいはさらなるコンシュームの為に新たな Kafka トピックへの変換されます。
例えば記事レコメンドの処理フローは次のようなものになるでしょう:
まず、RSS フィードから記事をクロールし、「記事」トピックに発行します。
続いて、内容を正規化したり重複を除いて、「クリーンな記事内容」トピックに発行します。
最後に、記事内容とユーザのマッチングを行ないます。
このような処理のフローは、個々のトピックから始まるリアルタイムデータフローのグラフを形成します。
<a href="https://storm.apache.org/">Storm</a> や <a href="http://samza.apache.org/">Samza</a> はこのような類の変換を行なうための有名なフレームワークです。
</p>
</div>
</div>

<div id="outline-container-sec-1-2-6" class="outline-4">
<h4 id="sec-1-2-6">イベントソーシング</h4>
<div class="outline-text-4" id="text-1-2-6">
<p>
<a href="http://martinfowler.com/eaaDev/EventSourcing.html">イベントソーシング</a> はアプリケーション設計手法のひとつで、
状態の変更が時系列順のレコード列として記録されるというものです。
Kafka は超巨大なログデータを扱えるため、
この手法で構築されたアプリケーションの優れたバックエンドとして利用することが出来ます。
</p>
</div>
</div>

<div id="outline-container-sec-1-2-7" class="outline-4">
<h4 id="sec-1-2-7">コミットログ</h4>
<div class="outline-text-4" id="text-1-2-7">
<p>
Kafka を分散システムのための外部コミットログとして使うこともできます。
ノード間でデータを複製したり、障害ノードの復旧のための再同期機構として、このログを利用することが出来ます。
Kafka の <a href="http://kafka.apache.org/documentation.html#compaction">ログコンパクション</a> 機能もこの用途に適しています。
この用途では、Kafka と <a href="http://zookeeper.apache.org/bookkeeper/">Apache BookKeeper</a> プロジェクトは似ています。
</p>
</div>
</div>
</div>

<div id="outline-container-sec-1-3" class="outline-3">
<h3 id="sec-1-3"><span class="section-number-3">1.3</span> クイックスタート</h3>
<div class="outline-text-3" id="text-1-3">
<p>
このチュートリアルは、まっさらな環境で、KafkaやZooKeeperが一切稼動していない前提で進めます。
</p>
</div>

<div id="outline-container-sec-1-3-1" class="outline-4">
<h4 id="sec-1-3-1">ステップ 1: コードのダウンロード</h4>
<div class="outline-text-4" id="text-1-3-1">
<p>
0.8.2.0 リリースを <a href="https://www.apache.org/dyn/closer.cgi?path=/kafka/0.8.2.0/kafka_2.10-0.8.2.0.tgz">ダウンロード</a> して、解凍しましょう。
</p>

<pre class="example">
&gt; tar -xzf kafka_2.10-0.8.2.0.tgz
&gt; cd kafka_2.10-0.8.2.0
</pre>
</div>
</div>

<div id="outline-container-sec-1-3-2" class="outline-4">
<h4 id="sec-1-3-2">ステップ 2: サーバの起動</h4>
<div class="outline-text-4" id="text-1-3-2">
<p>
Kafka は ZooKeeper を使うため、まずは ZooKeeper サーバを起動する必要があります。
既に起動している ZooKeeper サーバがある場合は、新たに起動する必要はありません。
新たに起動する場合は、 Kafka に同梱されている便利スクリプトを使ってください。
このスクリプトは、単一ノードを手早く作るための適当なものです。
</p>

<pre class="example">
&gt; bin/zookeeper-server-start.sh config/zookeeper.properties
[2013-04-22 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...
</pre>

<p>
では、 Kafka サーバを起動しましょう:
</p>

<pre class="example">
&gt; bin/kafka-server-start.sh config/server.properties
[2013-04-22 15:01:47,028] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2013-04-22 15:01:47,051] INFO Property socket.send.buffer.bytes is overridden to 1048576 (kafka.utils.VerifiableProperties)
...
</pre>
</div>
</div>

<div id="outline-container-sec-1-3-3" class="outline-4">
<h4 id="sec-1-3-3">ステップ 3: トピックの作成</h4>
<div class="outline-text-4" id="text-1-3-3">
<p>
今度は「test」という名前の、単一パーティションで、複製を作らないトピックを作成してみましょう:
</p>

<pre class="example">
&gt; bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
</pre>

<p>
list コマンドで、作成したトピックを参照できるようになるはずです:
</p>

<pre class="example">
&gt; bin/kafka-topics.sh --list --zookeeper localhost:2181
test
</pre>

<p>
また、手動でトピックを作成するのではなく、存在しないトピックへパブリッシュされた場合に自動で作成するようにブローカを設定することもできます。
</p>
</div>
</div>

<div id="outline-container-sec-1-3-4" class="outline-4">
<h4 id="sec-1-3-4">ステップ 4: メッセージを送ってみる</h4>
<div class="outline-text-4" id="text-1-3-4">
<p>
Kafka にはファイルか標準入力から Kafka クラスタにメッセージを送信出来るコマンドラインのクライアントが同梱されています。
デフォルトでは、各行がそれぞれ異なるメッセージとして送信されます。
</p>

<p>
プロデューサスクリプトを起動し、コンソールにメッセージを打ちこんでサーバに送信してみましょう。
<sup><a id="fnr.1" name="fnr.1" class="footref" href="#fn.1">1</a></sup>
</p>

<pre class="example">
&gt; bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
[2015-05-15 19:45:39,512] WARN Property topic is not valid (kafka.utils.VerifiableProperties)
これはメッセージです
これは別のメッセージです
^D
</pre>
</div>
</div>




<div id="outline-container-sec-1-3-5" class="outline-4">
<h4 id="sec-1-3-5">ステップ 5: コンシューマを起動する</h4>
<div class="outline-text-4" id="text-1-3-5">
<p>
Kafka にはメッセージを標準出力にダンプするコマンドラインのコンシューマも付属しています。
</p>

<pre class="example">
&gt; bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
これはメッセージです
これも別のメッセージです
^CConsumed 2 messages
</pre>

<p>
別々のターミナルで上記の両方のコマンドを実行すれば、プロデューサのターミナルでメッセージを打ち込むと、
コンシューマのターミナルでそれを確認することが出来ます。
</p>

<p>
全てのコマンドラインツールには追加のオプションがあります。
引数なしでコマンドを実行すると、より詳細が参照出来る使い方のドキュメントが出力されます。
</p>
</div>
</div>

<div id="outline-container-sec-1-3-6" class="outline-4">
<h4 id="sec-1-3-6">ステップ 6: マルチブローカクラスタを立ち上げる</h4>
<div class="outline-text-4" id="text-1-3-6">
<p>
ここまでは、単一のブローカ上で動作させて決ましたが、これではあまり面白くないですね。
単一のブローカというのは Kafka にとってはサイズ1のクラスタに過ぎないので、
複数のブローカインスタンスを起動することもそれほど違いはありません。
ですが、感覚を掴む為に3ノードのクラスタに拡張してみましょう(とはいえ、まだ全てのノードは同じローカルマシン上です)。
</p>

<p>
まず、各ブローカ用の設定ファイルを作ります:
</p>

<pre class="example">
&gt; cp config/server.properties config/server-1.properties
&gt; cp config/server.properties config/server-2.properties
</pre>

<p>
続いて、これらのファイルを編集して、以下のプロパティを設定します:
</p>

<pre class="example">
config/server-1.properties:
    broker.id=1
    port=9093
    log.dirs=/tmp/kafka-logs-1
</pre>

<pre class="example">
config/server-2.properties:
    broker.id=2
    port=9094
    log.dirs=/tmp/kafka-logs-2
</pre>

<p>
<code>broker.id</code> は、各ノードのクラスタ内でユニークな、永続的な名前を表すプロパティです。
ポート番号とログディレクトリだけは変更が必要です。
いま、これらのブローカは全て同一のマシン上で稼動しているので、
同じポート番号に登録しようとしたり、お互いのデータを上書きしあったりしてしまわないようにする必要があるためです。
</p>

<p>
既に ZooKeeper と単一ノードは起動しているので、3ノードのクラスタにするには、新しく2つのノードを立ち上げるだけです:
</p>

<pre class="example">
&gt; bin/kafka-server-start.sh config/server-1.properties &gt; /dev/null 2&gt;&amp;1 &amp;
...
&gt; bin/kafka-server-start.sh config/server-2.properties &gt; /dev/null 2&gt;&amp;1 &amp;
...
</pre>

<p>
では、レプリケーションファクタ3のトピックを作成してみます:
</p>

<pre class="example">
&gt; bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
</pre>

<p>
出来ました、が、クラスタ上のブローカの状態を見るにはどうすればよいのでしょう？
その為には "describe topics" コマンドを実行します:
</p>

<pre class="example">
&gt; bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 1	Replicas: 1,2,0	Isr: 1,2,0
</pre>

<p>
出力内容の説明をします。
最初の行が全パーティションの要約で、続く各行がそれぞれ1パーティションの情報を表します。
このトピックにはパーティションが一つしかないので、出力は1行しかありません。
</p>

<ul class="org-ul">
<li><code>Leader</code> はそのパーティションの全読み書きの責務を負うノードです。各ノードは、ランダムに選択されたパーティションのリーダになり得ます
</li>
<li><code>Replicas</code> はこのパーティションのログを複製しているノードのリストです。リーダか否か、現在生存しているノードかどうかにはかかわらず表示されます
</li>
<li><code>Isr</code> は「同期中」の複製を表します。 <code>Replicas</code> のリストのうち、現在生存しており、リーダに追い付いているノードが表示されます
</li>
</ul>

<p>
この例では、ノード1はこのトピックの唯一のパーティションのリーダであることに着目してください。
</p>

<p>
同じコマンドを最初に作ったトピックについて実行して、ブローカの状況を見てみましょう:
</p>

<pre class="example">
&gt; bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test
Topic:test	PartitionCount:1	ReplicationFactor:1	Configs:
	Topic: test	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
</pre>

<p>
特に変わったところはありません——このトピックは複製を一切持たず、元々クラスタを作成したときの唯一のノードである server 0 上にあります。
</p>

<p>
さて、新しく作った方のトピックにいくつかメッセージをパブリッシュしてみましょう:
</p>

<pre class="example">
&gt; bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic
...
my test message 1
my test message 2
^D
</pre>

<p>
続いてこれらのメッセージをコンシュームします:
</p>

<pre class="example">
&gt; bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic
...
my test message 1
my test message 2
^C
</pre>

<p>
ここで、耐障害性のテストをしてみましょう。
今はブローカ1がリーダなので、こいつを殺しましょう:
</p>

<pre class="example">
&gt; ps | grep server-1.properties
7564 ttys002    0:15.91 /System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/bin/java...
&gt; kill -9 7564
</pre>

<p>
リーダシップがスレーブノードの1つに移され、ノード1は <code>Isr</code> から外れます:
</p>

<pre class="example">
&gt; bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 2	Replicas: 1,2,0	Isr: 2,0
</pre>

<p>
元々の書き込みを引き受けたリーダがダウンしているにもかかわらず、なおメッセージはコンシューム可能です。
</p>

<pre class="example">
&gt; bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic
...
my test message 1
my test message 2
^C
</pre>
</div>
</div>
</div>

<div id="outline-container-sec-1-4" class="outline-3">
<h3 id="sec-1-4"><span class="section-number-3">1.4</span> エコシステム</h3>
<div class="outline-text-3" id="text-1-4">
<p>
メインディストリビューション外にも、Kafka 関連のツールが大量にあります。
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem">エコシステムのページ</a> に、ストリームプロセッシングシステムやHadoopとの統合、モニタリング、デプロイ等、
それらのツールの多くが列挙されています。
</p>
</div>
</div>

<div id="outline-container-sec-1-5" class="outline-3">
<h3 id="sec-1-5"><span class="section-number-3">1.5</span> 以前のバージョンからのアップグレード</h3>
<div class="outline-text-3" id="text-1-5">
</div><div id="outline-container-sec-1-5-1" class="outline-4">
<h4 id="sec-1-5-1">0.8.1 から 0.8.2.0 へのアップグレード</h4>
<div class="outline-text-4" id="text-1-5-1">
<p>
0.8.2.0 は 0.8.1 と完全に互換性があります。
単純に1台ずつブローカ停止し、コードを更新し、再起動することでアップグレード出来ます。
</p>
</div>
</div>

<div id="outline-container-sec-1-5-2" class="outline-4">
<h4 id="sec-1-5-2">0.8.0 から 0.8.1 へのアップグレード</h4>
<div class="outline-text-4" id="text-1-5-2">
<p>
0.8.1 は 0.8 と完全に互換性があります。
単純に1台ずつブローカ停止し、コードを更新し、再起動することでアップグレード出来ます。
</p>
</div>
</div>

<div id="outline-container-sec-1-5-3" class="outline-4">
<h4 id="sec-1-5-3">0.7 からのアップグレード</h4>
<div class="outline-text-4" id="text-1-5-3">
<p>
レプリケーションが追加された 0.8 は、初めて後方互換性が失われたリリースでした。
API、 ZooKeeper のデータ構造、プロトコル、設定に主要な変更が入りました。
</p>

<p>
0.7 から 0.8.x へのアップグレードには、移行のための <a href="https://cwiki.apache.org/confluence/display/KAFKA/Migrating+from+0.7+to+0.8">特別なツール</a> が必要です。
移行は無停止で行なうことが可能です。
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> API</h2>
<div class="outline-text-2" id="text-2">
<p>
現在 Kafka の JVM クライアントをリライト中です。
0.8.2 では、新規に書き直された Java プロデューサーが同梱されています。
次期リリースでは同様に Java コンシューマを含める予定です。
これらの新しいクライアントは既存の Scala クライアントを置き換えるものとなる見込みですが、
互換性のためにしばらくは共存することになります。
これらのクライアントは別のjarで提供され、最低限の依存関係だけが定義されています。
過去の Scala クライアントは、サーバと同じパッケージに同梱されていました。
<sup><a id="fnr.2" name="fnr.2" class="footref" href="#fn.2">2</a></sup>
</p>
</div>

<div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1"><span class="section-number-3">2.1</span> プロデューサ API</h3>
<div class="outline-text-3" id="text-2-1">
<p>
0.8.2 では、新規開発には新しい Java プロデューサを使うことを強くお奨めします。
これは実稼動環境での試験が済んでおり、一般的に以前の Scala クライアントよりも高速で高機能です。
以下のように、クライアント jar への依存を maven の pom に指定することで利用できます:
</p>

<div class="org-src-container">

<pre class="src src-xml"><span class="org-nxml-tag-delimiter">&lt;</span><span class="org-nxml-element-local-name">dependency</span><span class="org-nxml-tag-delimiter">&gt;</span>
    <span class="org-nxml-tag-delimiter">&lt;</span><span class="org-nxml-element-local-name">groupId</span><span class="org-nxml-tag-delimiter">&gt;</span><span class="org-nxml-text">org.apache.kafka</span><span class="org-nxml-tag-delimiter">&lt;</span><span class="org-nxml-tag-slash">/</span><span class="org-nxml-element-local-name">groupId</span><span class="org-nxml-tag-delimiter">&gt;</span>
    <span class="org-nxml-tag-delimiter">&lt;</span><span class="org-nxml-element-local-name">artifactId</span><span class="org-nxml-tag-delimiter">&gt;</span><span class="org-nxml-text">kafka-clients</span><span class="org-nxml-tag-delimiter">&lt;</span><span class="org-nxml-tag-slash">/</span><span class="org-nxml-element-local-name">artifactId</span><span class="org-nxml-tag-delimiter">&gt;</span>
    <span class="org-nxml-tag-delimiter">&lt;</span><span class="org-nxml-element-local-name">version</span><span class="org-nxml-tag-delimiter">&gt;</span><span class="org-nxml-text">0.8.2.0</span><span class="org-nxml-tag-delimiter">&lt;</span><span class="org-nxml-tag-slash">/</span><span class="org-nxml-element-local-name">version</span><span class="org-nxml-tag-delimiter">&gt;</span>
<span class="org-nxml-tag-delimiter">&lt;</span><span class="org-nxml-tag-slash">/</span><span class="org-nxml-element-local-name">dependency</span><span class="org-nxml-tag-delimiter">&gt;</span>
</pre>
</div>

<p>
使い方や使用例は <a href="http://kafka.apache.org/082/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html">javadoc</a> に書かれています。
</p>

<p>
レガシーな Scala プロデューサ API についてもし興味があれば、 <a href="http://kafka.apache.org/081/documentation.html#producerapi">ここ</a> を参照してください。
</p>
</div>
</div>

<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2"><span class="section-number-3">2.2</span> ハイレベルコンシューマ API</h3>
<div class="outline-text-3" id="text-2-2">
<div class="org-src-container">

<pre class="src src-java"><span class="org-keyword">class</span> <span class="org-type">Consumer</span> <span class="org-rainbow-delimiters-depth-1">{</span>
  <span class="org-doc">/**</span>
<span class="org-doc">   *  ConsumerConnector &#12398;&#20316;&#25104;</span>
<span class="org-doc">   *</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@param</span></span><span class="org-doc"> config  &#12467;&#12531;&#12471;&#12517;&#12540;&#12510;&#12398; groupid &#12392;&#12289; ZooKeeper &#12392;&#12398;&#25509;&#32154;&#24773;&#22577;&#25991;&#23383;&#21015; zookeeper.connect &#12364;&#12289;</span>
<span class="org-doc">   *                 &#26368;&#20302;&#38480;&#24517;&#35201;</span>
<span class="org-doc">   */</span>
  <span class="org-keyword">public</span> <span class="org-keyword">static</span> <span class="org-constant">kafka</span>.<span class="org-constant">javaapi</span>.<span class="org-constant">consumer</span>.<span class="org-type">ConsumerConnector</span> <span class="org-function-name">createJavaConsumerConnector</span><span class="org-rainbow-delimiters-depth-2">(</span><span class="org-type">ConsumerConfig</span> <span class="org-variable-name">config</span><span class="org-rainbow-delimiters-depth-2">)</span>;
<span class="org-rainbow-delimiters-depth-1">}</span>

<span class="org-doc">/**</span>
<span class="org-doc"> *  V: &#12513;&#12483;&#12475;&#12540;&#12472;&#12398;&#22411;</span>
<span class="org-doc"> *  K: &#12513;&#12483;&#12475;&#12540;&#12472;&#12395;&#38306;&#36899;&#20184;&#12369;&#12425;&#12428;&#12383;&#12458;&#12503;&#12471;&#12519;&#12490;&#12523;&#12394;&#12461;&#12540;</span>
<span class="org-doc"> */</span>
<span class="org-keyword">public</span> <span class="org-keyword">interface</span> <span class="org-constant">kafka</span>.<span class="org-constant">javaapi</span>.<span class="org-constant">consumer</span>.<span class="org-type">ConsumerConnector</span> <span class="org-rainbow-delimiters-depth-1">{</span>
  <span class="org-doc">/**</span>
<span class="org-doc">   *  &#12488;&#12500;&#12483;&#12463;&#27598;&#12395; </span><span class="org-doc"><span class="org-warning">&lt;</span></span><span class="org-doc">K,V</span><span class="org-doc"><span class="org-warning">&gt;</span></span><span class="org-doc"> &#22411;&#12398;&#12513;&#12483;&#12475;&#12540;&#12472;&#12473;&#12488;&#12522;&#12540;&#12512;&#12398;&#12522;&#12473;&#12488;&#12434;&#29983;&#25104;&#12377;&#12427;&#12290;</span>
<span class="org-doc">   *</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@param</span></span><span class="org-doc"> topicCountMap  (&#12488;&#12500;&#12483;&#12463;, &#12473;&#12488;&#12522;&#12540;&#12512;&#25968;) &#12398; Map</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@param</span></span><span class="org-doc"> keyDecoder &#12496;&#12452;&#12488;&#21015;&#12398; Message &#12434; K &#22411;&#12408;&#22793;&#25563;&#12377;&#12427;&#12487;&#12467;&#12540;&#12480;</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@param</span></span><span class="org-doc"> valueDecoder &#12496;&#12452;&#12488;&#21015;&#12398; Message &#12363;&#12425; V &#22411;&#12408;&#22793;&#25563;&#12377;&#12427;&#12487;&#12467;&#12540;&#12480;</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@return</span></span><span class="org-doc"> (&#12488;&#12500;&#12483;&#12463;, KafkaStream &#12398;&#12522;&#12473;&#12488;) &#12398; Map&#12290;</span>
<span class="org-doc">   *          &#12522;&#12473;&#12488;&#12398;&#35201;&#32032;&#25968;&#12399;&#12473;&#12488;&#12522;&#12540;&#12512;&#25968;&#12392;&#12394;&#12427;&#12290;</span>
<span class="org-doc">   *          &#21508;&#12473;&#12488;&#12522;&#12540;&#12512;&#12399; (&#12513;&#12483;&#12475;&#12540;&#12472;, &#12513;&#12479;&#12487;&#12540;&#12479;) &#12398;&#12506;&#12450; (MessageAndMetadata) &#12398;&#12452;&#12486;&#12524;&#12540;&#12479;&#12434;&#12469;&#12509;&#12540;&#12488;&#12377;&#12427;&#12290;</span>
<span class="org-doc">   */</span>
  <span class="org-keyword">public</span> &lt;<span class="org-type">K</span>,<span class="org-type">V</span>&gt; <span class="org-type">Map</span>&lt;<span class="org-type">String</span>, <span class="org-type">List</span>&lt;<span class="org-type">KafkaStream</span>&lt;<span class="org-type">K</span>,<span class="org-type">V</span>&gt;&gt;&gt;
    <span class="org-function-name">createMessageStreams</span><span class="org-rainbow-delimiters-depth-2">(</span><span class="org-type">Map</span>&lt;<span class="org-type">String</span>, <span class="org-type">Integer</span>&gt; <span class="org-variable-name">topicCountMap</span>, <span class="org-type">Decoder</span>&lt;<span class="org-type">K</span>&gt; <span class="org-variable-name">keyDecoder</span>, <span class="org-type">Decoder</span>&lt;<span class="org-type">V</span>&gt; <span class="org-variable-name">valueDecoder</span><span class="org-rainbow-delimiters-depth-2">)</span>;

  <span class="org-doc">/**</span>
<span class="org-doc">   *  &#12487;&#12501;&#12457;&#12523;&#12488;&#12398;&#12487;&#12467;&#12540;&#12480;&#12391;&#12488;&#12500;&#12483;&#12463;&#27598;&#12398;&#12473;&#12488;&#12522;&#12540;&#12512;&#12398;&#12522;&#12473;&#12488;&#12434;&#20316;&#25104;&#12377;&#12427;&#12290;</span>
<span class="org-doc">   */</span>
  <span class="org-keyword">public</span> <span class="org-type">Map</span>&lt;<span class="org-type">String</span>, <span class="org-type">List</span>&lt;<span class="org-type">KafkaStream</span>&lt;<span class="org-type">byte</span><span class="org-rainbow-delimiters-depth-2">[]</span>, <span class="org-type">byte</span><span class="org-rainbow-delimiters-depth-2">[]</span>&gt;&gt;&gt; <span class="org-function-name">createMessageStreams</span><span class="org-rainbow-delimiters-depth-2">(</span><span class="org-type">Map</span>&lt;<span class="org-type">String</span>, <span class="org-type">Integer</span>&gt; <span class="org-variable-name">topicCountMap</span><span class="org-rainbow-delimiters-depth-2">)</span>;

  <span class="org-doc">/**</span>
<span class="org-doc">   *  &#12527;&#12452;&#12523;&#12489;&#12459;&#12540;&#12489;&#12395;&#12510;&#12483;&#12481;&#12375;&#12383;&#12488;&#12500;&#12483;&#12463;&#12398;&#12513;&#12483;&#12475;&#12540;&#12472;&#12473;&#12488;&#12522;&#12540;&#12512;&#12398;&#12522;&#12473;&#12488;&#12434;&#20316;&#25104;&#12377;&#12427;&#12290; </span>
<span class="org-doc">   *</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@param</span></span><span class="org-doc"> topicFilter &#12393;&#12398;&#12488;&#12500;&#12483;&#12463;&#12434;&#36092;&#35501;&#12377;&#12427;&#12363;&#12434;&#29305;&#23450;&#12377;&#12427; TopicFilter</span>
<span class="org-doc">   *                     (&#12507;&#12527;&#12452;&#12488;&#12522;&#12473;&#12488;&#26041;&#24335;&#12363;&#12502;&#12521;&#12483;&#12463;&#12522;&#12473;&#12488;&#26041;&#24335;&#12363;&#12434;&#38560;&#34109;&#12375;&#12390;&#12356;&#12427;)&#12290;</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@param</span></span><span class="org-doc"> numStreams &#36820;&#12377;&#12513;&#12483;&#12475;&#12540;&#12472;&#12473;&#12488;&#12522;&#12540;&#12512;&#12398;&#25968;</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@param</span></span><span class="org-doc"> keyDecoder &#12513;&#12483;&#12475;&#12540;&#12472;&#12461;&#12540;&#12434;&#12487;&#12467;&#12540;&#12489;&#12377;&#12427;&#12487;&#12467;&#12540;&#12480;</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@param</span></span><span class="org-doc"> valueDecoder &#12513;&#12483;&#12475;&#12540;&#12472;&#33258;&#36523;&#12434;&#12487;&#12467;&#12540;&#12489;&#12377;&#12427;&#12487;&#12467;&#12540;&#12480;</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@return</span></span><span class="org-doc"> KafkaStream &#12398;&#12522;&#12473;&#12488;&#12290;</span>
<span class="org-doc">   *          &#21508;&#12473;&#12488;&#12522;&#12540;&#12512;&#12399; MessageAndMetadata &#35201;&#32032;&#12398;&#12452;&#12486;&#12524;&#12540;&#12479;&#12434;&#12469;&#12509;&#12540;&#12488;&#12377;&#12427;&#12290;</span>
<span class="org-doc">   */</span>
  <span class="org-keyword">public</span> &lt;<span class="org-type">K</span>,<span class="org-type">V</span>&gt; <span class="org-type">List</span>&lt;<span class="org-type">KafkaStream</span>&lt;<span class="org-type">K</span>,<span class="org-type">V</span>&gt;&gt;
    <span class="org-function-name">createMessageStreamsByFilter</span><span class="org-rainbow-delimiters-depth-2">(</span><span class="org-type">TopicFilter</span> <span class="org-variable-name">topicFilter</span>, <span class="org-type">int</span> <span class="org-variable-name">numStreams</span>, <span class="org-type">Decoder</span>&lt;<span class="org-type">K</span>&gt; <span class="org-variable-name">keyDecoder</span>, <span class="org-type">Decoder</span>&lt;<span class="org-type">V</span>&gt; <span class="org-variable-name">valueDecoder</span><span class="org-rainbow-delimiters-depth-2">)</span>;

  <span class="org-doc">/**</span>
<span class="org-doc">   *  &#12487;&#12501;&#12457;&#12523;&#12488;&#12398;&#12487;&#12467;&#12540;&#12480;&#12391;&#12527;&#12452;&#12523;&#12489;&#12459;&#12540;&#12489;&#12395;&#12510;&#12483;&#12481;&#12375;&#12383;&#12488;&#12500;&#12483;&#12463;&#12398;&#12513;&#12483;&#12475;&#12540;&#12472;&#12473;&#12488;&#12522;&#12540;&#12512;&#12398;&#12522;&#12473;&#12488;&#12434;&#20316;&#25104;&#12377;&#12427;&#12290; </span>
<span class="org-doc">   */</span>
  <span class="org-keyword">public</span> <span class="org-type">List</span>&lt;<span class="org-type">KafkaStream</span>&lt;<span class="org-type">byte</span><span class="org-rainbow-delimiters-depth-2">[]</span>, <span class="org-type">byte</span><span class="org-rainbow-delimiters-depth-2">[]</span>&gt;&gt; <span class="org-function-name">createMessageStreamsByFilter</span><span class="org-rainbow-delimiters-depth-2">(</span><span class="org-type">TopicFilter</span> <span class="org-variable-name">topicFilter</span>, <span class="org-type">int</span> <span class="org-variable-name">numStreams</span><span class="org-rainbow-delimiters-depth-2">)</span>;

  <span class="org-doc">/**</span>
<span class="org-doc">   *  &#12527;&#12452;&#12523;&#12489;&#12459;&#12540;&#12489;&#12395;&#12510;&#12483;&#12481;&#12375;&#12383;&#12488;&#12500;&#12483;&#12463;&#12398;&#12513;&#12483;&#12475;&#12540;&#12472;&#12473;&#12488;&#12522;&#12540;&#12512;&#12434;&#12487;&#12501;&#12457;&#12523;&#12488;&#12398;&#12487;&#12467;&#12540;&#12480;&#12391;&#19968;&#12388;&#12384;&#12369;&#20316;&#25104;&#12377;&#12427;&#12290;</span>
<span class="org-doc">   */</span>
  <span class="org-keyword">public</span> <span class="org-type">List</span>&lt;<span class="org-type">KafkaStream</span>&lt;<span class="org-type">byte</span><span class="org-rainbow-delimiters-depth-2">[]</span>, <span class="org-type">byte</span><span class="org-rainbow-delimiters-depth-2">[]</span>&gt;&gt; <span class="org-function-name">createMessageStreamsByFilter</span><span class="org-rainbow-delimiters-depth-2">(</span><span class="org-type">TopicFilter</span> <span class="org-variable-name">topicFilter</span><span class="org-rainbow-delimiters-depth-2">)</span>;

  <span class="org-doc">/**</span>
<span class="org-doc">   *  &#12371;&#12398;&#12467;&#12493;&#12463;&#12479;&#12391;&#25509;&#32154;&#12375;&#12390;&#12356;&#12427;&#20840;&#12390;&#12398;&#12488;&#12500;&#12483;&#12463;/&#12497;&#12540;&#12486;&#12451;&#12471;&#12519;&#12531;&#12398;&#12458;&#12501;&#12475;&#12483;&#12488;&#12434;&#12467;&#12511;&#12483;&#12488;&#12377;&#12427;</span>
<span class="org-doc">   */</span>
  <span class="org-keyword">public</span> <span class="org-type">void</span> <span class="org-function-name">commitOffsets</span><span class="org-rainbow-delimiters-depth-2">()</span>;

  <span class="org-doc">/**</span>
<span class="org-doc">   *  &#12467;&#12493;&#12463;&#12479;&#12434;&#12471;&#12515;&#12483;&#12488;&#12480;&#12454;&#12531;&#12377;&#12427;</span>
<span class="org-doc">   */</span>
  <span class="org-keyword">public</span> <span class="org-type">void</span> <span class="org-function-name">shutdown</span><span class="org-rainbow-delimiters-depth-2">()</span>;
<span class="org-rainbow-delimiters-depth-1">}</span>
</pre>
</div>

<p>
<sup><a id="fnr.3" name="fnr.3" class="footref" href="#fn.3">3</a></sup>
</p>

<p>
ハイレベルコンシューマ API の使い方を習得するには、<a href="https://cwiki.apache.org/confluence/display/KAFKA/Consumer+Group+Example">この例</a> を参照して下さい。
</p>
</div>
</div>

<div id="outline-container-sec-2-3" class="outline-3">
<h3 id="sec-2-3"><span class="section-number-3">2.3</span> シンプルコンシューマ API</h3>
<div class="outline-text-3" id="text-2-3">
<div class="org-src-container">

<pre class="src src-java"><span class="org-keyword">class</span> <span class="org-constant">kafka</span>.<span class="org-constant">javaapi</span>.<span class="org-constant">consumer</span>.<span class="org-type">SimpleConsumer</span> <span class="org-rainbow-delimiters-depth-1">{</span>
  <span class="org-doc">/**</span>
<span class="org-doc">   *  &#12488;&#12500;&#12483;&#12463;&#12363;&#12425;&#12513;&#12483;&#12475;&#12540;&#12472;&#12398;&#12475;&#12483;&#12488;&#12434;&#21462;&#24471;&#12377;&#12427;&#12290;</span>
<span class="org-doc">   *</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@param</span></span><span class="org-doc"> &#21462;&#24471;&#12377;&#12427;&#12488;&#12500;&#12483;&#12463;&#21517;&#12289;&#12497;&#12540;&#12486;&#12451;&#12471;&#12519;&#12531;&#12289;&#38283;&#22987;&#12496;&#12452;&#12488;&#12458;&#12501;&#12475;&#12483;&#12488;&#12289;&#26368;&#22823;&#12496;&#12452;&#12488;&#12434;&#25351;&#23450;&#12377;&#12427;&#12522;&#12463;&#12456;&#12473;&#12488;</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@return</span></span><span class="org-doc"> &#21462;&#24471;&#12375;&#12383;&#12513;&#12483;&#12475;&#12540;&#12472;&#12398;&#12475;&#12483;&#12488;</span>
<span class="org-doc">   */</span>
  <span class="org-keyword">public</span> <span class="org-type">FetchResponse</span> <span class="org-function-name">fetch</span><span class="org-rainbow-delimiters-depth-2">(</span><span class="org-constant">kafka</span>.<span class="org-constant">javaapi</span>.<span class="org-type">FetchRequest</span> <span class="org-variable-name">request</span><span class="org-rainbow-delimiters-depth-2">)</span>;

  <span class="org-doc">/**</span>
<span class="org-doc">   *  &#35079;&#25968;&#12488;&#12500;&#12483;&#12463;&#12398;&#12513;&#12479;&#12487;&#12540;&#12479;&#12434;&#21462;&#24471;&#12377;&#12427;&#12290;</span>
<span class="org-doc">   *</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@param</span></span><span class="org-doc"> &#21462;&#24471;&#12377;&#12427; versionId, clientId, topic &#12398;&#12471;&#12540;&#12465;&#12531;&#12473;&#12434;&#25351;&#23450;&#12377;&#12427;&#12522;&#12463;&#12456;&#12473;&#12488;&#12290;</span>
<span class="org-doc">   *  </span><span class="org-doc"><span class="org-constant">@return</span></span><span class="org-doc"> &#12522;&#12463;&#12456;&#12473;&#12488;&#12373;&#12428;&#12383;&#21508;&#12488;&#12500;&#12483;&#12463;&#12398;&#12513;&#12479;&#12487;&#12540;&#12479;&#12290;</span>
<span class="org-doc">   */</span>
  <span class="org-keyword">public</span> <span class="org-constant">kafka</span>.<span class="org-constant">javaapi</span>.<span class="org-type">TopicMetadataResponse</span> <span class="org-function-name">send</span><span class="org-rainbow-delimiters-depth-2">(</span><span class="org-constant">kafka</span>.<span class="org-constant">javaapi</span>.<span class="org-type">TopicMetadataRequest</span> <span class="org-variable-name">request</span><span class="org-rainbow-delimiters-depth-2">)</span>;

  <span class="org-doc">/**</span>
<span class="org-doc">   *  &#19982;&#12360;&#12425;&#12428;&#12383;&#26178;&#21051;&#12424;&#12426;&#20197;&#21069;&#12398;(maxSize&#20197;&#19979;&#12398;)&#22949;&#24403;&#12394;&#12458;&#12501;&#12475;&#12483;&#12488;&#12398;&#12522;&#12473;&#12488;&#12434;&#21462;&#24471;&#12377;&#12427;&#12290;</span>
<span class="org-doc">   */</span>
  <span class="org-keyword">public</span> <span class="org-constant">kafak</span>.<span class="org-constant">javaapi</span>.<span class="org-type">OffsetResponse</span> <span class="org-function-name">getOffsetsBefore</span><span class="org-rainbow-delimiters-depth-2">(</span><span class="org-type">OffsetRequest</span> <span class="org-variable-name">request</span><span class="org-rainbow-delimiters-depth-2">)</span>;

  <span class="org-doc">/**</span>
<span class="org-doc">   * &#12471;&#12531;&#12503;&#12523;&#12467;&#12531;&#12471;&#12517;&#12540;&#12510;&#12434;&#12463;&#12525;&#12540;&#12474;&#12377;&#12427;&#12290;</span>
<span class="org-doc">   */</span>
  <span class="org-keyword">public</span> <span class="org-type">void</span> <span class="org-function-name">close</span><span class="org-rainbow-delimiters-depth-2">()</span>;
<span class="org-rainbow-delimiters-depth-1">}</span>
</pre>
</div>

<p>
<sup><a id="fnr.4" name="fnr.4" class="footref" href="#fn.4">4</a></sup>
</p>

<p>
ほとんどのアプリケーションはハイレベルコンシューマ API で十分でしょう。
ハイレベルコンシューマではまだ提供されていない機能を利用したいアプリケーションもあるかもしれません
(例えば、 再起動時の初期オフセットを設定するなど)。
その場合は低レベルな SimpleConsumer Api を利用出来ます。
利用する際のロジックはより複雑になります。
<a href="https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example">こちら</a> の例に従ってやってみてください。
</p>
</div>
</div>

<div id="outline-container-sec-2-4" class="outline-3">
<h3 id="sec-2-4"><span class="section-number-3">2.4</span> Kafka Hadoop コンシューマ API</h3>
<div class="outline-text-3" id="text-2-4">
<p>
データを集約し Hadoop に保存する、水平スケールするソリューションを提供するというのは、基本的なユースケースでした。
このユースケースをサポートするため、
Kafka クラスタから並列にデータを取得する大量のマップタスクを起動させる、Hadoop ベースのコンシューマを提供しています。
これにより高速なプルペースの Hadoop データロードが実現できます
(ごく少ない Kafka サーバだけでネットワーク帯域を完全に使い切ることが出来ていました)。
</p>

<p>
Hadoop コンシューマの使用方法は <a href="https://github.com/linkedin/camus/">こちら</a> です。
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> 設定</h2>
<div class="outline-text-2" id="text-3">
<p>
Kafka は  <a href="http://en.wikipedia.org/wiki/.properties">プロパティファイルフォーマット</a> の key-value ペアで設定を行ないます。
これらの値はファイル、もしくはプログラム中で設定することが出来ます。
</p>
</div>

<div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1"><span class="section-number-3">3.1</span> ブローカ設定</h3>
<div class="outline-text-3" id="text-3-1">
<p>
最低限の設定値は以下の3つです:
</p>

<ul class="org-ul">
<li><code>broker.id</code>
</li>
<li><code>log.dirs</code>
</li>
<li><code>zookeeper.connect</code>
</li>
</ul>

<p>
トピックレベルの設定とデフォルト値の詳細については <a href="#topic-config">後述</a> します。
</p>
</div>

<div id="outline-container-sec-3-1-1" class="outline-4">
<h4 id="sec-3-1-1"><code>broker.id</code></h4>
<div class="outline-text-4" id="text-3-1-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">&#xa0;</td>
</tr>
</tbody>
</table>

<p>
各ブローカは非負整数の ID により一意に識別されます。
この ID はブローカの「名前」として使われ、
そのブローカが異なるホスト/ポートに移動した際にもコンシューマは混乱なく利用出来るようになります。
</p>

<p>
クラスタ内でユニークでありさえすれば任意の数値を設定できます。
</p>
</div>
</div>

<div id="outline-container-sec-3-1-2" class="outline-4">
<h4 id="sec-3-1-2"><code>log.dirs</code></h4>
<div class="outline-text-4" id="text-3-1-2">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">/tmp/kafka-logs</td>
</tr>
</tbody>
</table>

<p>
Kafka のデータが保存される1つ以上のディレクトリです。
複数指定する際はカンマで区切って指定します。
新しく作られた各パーティションは、
その時点で最もパーティションが少ないディレクトリに配置されます。
</p>
</div>
</div>

<div id="outline-container-sec-3-1-3" class="outline-4">
<h4 id="sec-3-1-3">port</h4>
<div class="outline-text-4" id="text-3-1-3">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">9092</td>
</tr>
</tbody>
</table>
<p>
The port on which the server accepts client connections.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-4" class="outline-4">
<h4 id="sec-3-1-4">zookeeper.connect</h4>
<div class="outline-text-4" id="text-3-1-4">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">null</td>
</tr>
</tbody>
</table>
<p>
Specifies the ZooKeeper connection string in the form hostname:port, where hostname and port are the host and port for a node in your ZooKeeper cluster. To allow connecting through other ZooKeeper nodes when that host is down you can also specify multiple hosts in the form <code>hostname1:port1,hostname2:port2,hostname3:port3</code>.
</p>

<p>
ZooKeeper also allows you to add a "chroot" path which will make all kafka data for this cluster appear under a particular path. This is a way to setup multiple Kafka clusters or other applications on the same ZooKeeper cluster. To do this give a connection string in the form <code>hostname1:port1,hostname2:port2,hostname3:port3/chroot/path</code> which would put all this cluster's data under the path <code>/chroot/path</code>. Note that you must create this path yourself prior to starting the broker and consumers must use the same connection string.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-5" class="outline-4">
<h4 id="sec-3-1-5">message.max.bytes</h4>
<div class="outline-text-4" id="text-3-1-5">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">1000000</td>
</tr>
</tbody>
</table>
<p>
The maximum size of a message that the server can receive. It is important that this property be in sync with the maximum fetch size your consumers use or else an unruly producer will be able to publish messages too large for consumers to consume.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-6" class="outline-4">
<h4 id="sec-3-1-6">num.network.threads</h4>
<div class="outline-text-4" id="text-3-1-6">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">3</td>
</tr>
</tbody>
</table>
<p>
The number of network threads that the server uses for handling network requests. You probably don't need to change this.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-7" class="outline-4">
<h4 id="sec-3-1-7">num.io.threads</h4>
<div class="outline-text-4" id="text-3-1-7">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">8</td>
</tr>
</tbody>
</table>
<p>
The number of I/O threads that the server uses for executing requests. You should have at least as many threads as you have disks.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-8" class="outline-4">
<h4 id="sec-3-1-8">background.threads</h4>
<div class="outline-text-4" id="text-3-1-8">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">10</td>
</tr>
</tbody>
</table>
<p>
The number of threads to use for various background processing tasks such as file deletion. You should not need to change this.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-9" class="outline-4">
<h4 id="sec-3-1-9">queued.max.requests</h4>
<div class="outline-text-4" id="text-3-1-9">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">500</td>
</tr>
</tbody>
</table>
<p>
The number of requests that can be queued up for processing by the I/O threads before the network threads stop reading in new requests.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-10" class="outline-4">
<h4 id="sec-3-1-10">host.name</h4>
<div class="outline-text-4" id="text-3-1-10">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">null</td>
</tr>
</tbody>
</table>
<p>
Hostname of broker. If this is set, it will only bind to this address. If this is not set, it will bind to all interfaces, and publish one to ZK.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-11" class="outline-4">
<h4 id="sec-3-1-11">advertised.host.name</h4>
<div class="outline-text-4" id="text-3-1-11">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">null</td>
</tr>
</tbody>
</table>
<p>
If this is set this is the hostname that will be given out to producers, consumers, and other brokers to connect to.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-12" class="outline-4">
<h4 id="sec-3-1-12">advertised.port</h4>
<div class="outline-text-4" id="text-3-1-12">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">null</td>
</tr>
</tbody>
</table>
<p>
The port to give out to producers, consumers, and other brokers to use in establishing connections. This only needs to be set if this port is different from the port the server should bind to.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-13" class="outline-4">
<h4 id="sec-3-1-13">socket.send.buffer.bytes</h4>
<div class="outline-text-4" id="text-3-1-13">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">100 * 1024</td>
</tr>
</tbody>
</table>
<p>
The SO<sub>SNDBUFF</sub> buffer the server prefers for socket connections.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-14" class="outline-4">
<h4 id="sec-3-1-14">socket.receive.buffer.bytes</h4>
<div class="outline-text-4" id="text-3-1-14">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">100 * 1024</td>
</tr>
</tbody>
</table>
<p>
The SO<sub>RCVBUFF</sub> buffer the server prefers for socket connections.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-15" class="outline-4">
<h4 id="sec-3-1-15">socket.request.max.bytes</h4>
<div class="outline-text-4" id="text-3-1-15">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">100 * 1024 * 1024</td>
</tr>
</tbody>
</table>
<p>
The maximum request size the server will allow. This prevents the server from running out of memory and should be smaller than the Java heap size.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-16" class="outline-4">
<h4 id="sec-3-1-16">num.partitions</h4>
<div class="outline-text-4" id="text-3-1-16">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">1</td>
</tr>
</tbody>
</table>
<p>
The default number of partitions per topic if a partition count isn't given at topic creation time.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-17" class="outline-4">
<h4 id="sec-3-1-17">log.segment.bytes</h4>
<div class="outline-text-4" id="text-3-1-17">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">1024 * 1024 * 1024</td>
</tr>
</tbody>
</table>
<p>
The log for a topic partition is stored as a directory of segment files. This setting controls the size to which a segment file will grow before a new segment is rolled over in the log. This setting can be overridden on a per-topic basis (see the per-topic configuration section).
</p>
</div>
</div>
<div id="outline-container-sec-3-1-18" class="outline-4">
<h4 id="sec-3-1-18">log.roll.{ms,hours}</h4>
<div class="outline-text-4" id="text-3-1-18">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">24 * 7 hours</td>
</tr>
</tbody>
</table>
<p>
This setting will force Kafka to roll a new log segment even if the log.segment.bytes size has not been reached. This setting can be overridden on a per-topic basis (see the per-topic configuration section).
</p>
</div>
</div>
<div id="outline-container-sec-3-1-19" class="outline-4">
<h4 id="sec-3-1-19">log.cleanup.policy</h4>
<div class="outline-text-4" id="text-3-1-19">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">delete</td>
</tr>
</tbody>
</table>
<p>
This can take either the value delete or compact. If delete is set, log segments will be deleted when they reach the size or time limits set. If compact is set log compaction will be used to clean out obsolete records. This setting can be overridden on a per-topic basis (see the per-topic configuration section).
</p>
</div>
</div>
<div id="outline-container-sec-3-1-20" class="outline-4">
<h4 id="sec-3-1-20">log.retention.{ms,minutes,hours}</h4>
<div class="outline-text-4" id="text-3-1-20">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">7 days</td>
</tr>
</tbody>
</table>
<p>
The amount of time to keep a log segment before it is deleted, i.e. the default data retention window for all topics. Note that if both log.retention.minutes and log.retention.bytes are both set we delete a segment when either limit is exceeded. This setting can be overridden on a per-topic basis (see the per-topic configuration section).
</p>
</div>
</div>
<div id="outline-container-sec-3-1-21" class="outline-4">
<h4 id="sec-3-1-21">log.retention.bytes</h4>
<div class="outline-text-4" id="text-3-1-21">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">-1</td>
</tr>
</tbody>
</table>
<p>
The amount of data to retain in the log for each topic-partitions. Note that this is the limit per-partition so multiply by the number of partitions to get the total data retained for the topic. Also note that if both log.retention.hours and log.retention.bytes are both set we delete a segment when either limit is exceeded. This setting can be overridden on a per-topic basis (see the per-topic configuration section).
</p>
</div>
</div>
<div id="outline-container-sec-3-1-22" class="outline-4">
<h4 id="sec-3-1-22">log.retention.check.interval.ms</h4>
<div class="outline-text-4" id="text-3-1-22">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">5 minutes</td>
</tr>
</tbody>
</table>
<p>
The period with which we check whether any log segment is eligible for deletion to meet the retention policies.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-23" class="outline-4">
<h4 id="sec-3-1-23">log.cleaner.enable</h4>
<div class="outline-text-4" id="text-3-1-23">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">false</td>
</tr>
</tbody>
</table>
<p>
This configuration must be set to true for log compaction to run.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-24" class="outline-4">
<h4 id="sec-3-1-24">log.cleaner.threads</h4>
<div class="outline-text-4" id="text-3-1-24">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">1</td>
</tr>
</tbody>
</table>
<p>
The number of threads to use for cleaning logs in log compaction.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-25" class="outline-4">
<h4 id="sec-3-1-25">log.cleaner.io.max.bytes.per.second</h4>
<div class="outline-text-4" id="text-3-1-25">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">Double.MaxValue</td>
</tr>
</tbody>
</table>
<p>
The maximum amount of I/O the log cleaner can do while performing log compaction. This setting allows setting a limit for the cleaner to avoid impacting live request serving.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-26" class="outline-4">
<h4 id="sec-3-1-26">log.cleaner.dedupe.buffer.size</h4>
<div class="outline-text-4" id="text-3-1-26">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">500*1024*1024</td>
</tr>
</tbody>
</table>
<p>
The size of the buffer the log cleaner uses for indexing and deduplicating logs during cleaning. Larger is better provided you have sufficient memory.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-27" class="outline-4">
<h4 id="sec-3-1-27">log.cleaner.io.buffer.size</h4>
<div class="outline-text-4" id="text-3-1-27">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">512*1024</td>
</tr>
</tbody>
</table>
<p>
The size of the I/O chunk used during log cleaning. You probably don't need to change this.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-28" class="outline-4">
<h4 id="sec-3-1-28">log.cleaner.io.buffer.load.factor</h4>
<div class="outline-text-4" id="text-3-1-28">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">0.9</td>
</tr>
</tbody>
</table>
<p>
The load factor of the hash table used in log cleaning. You probably don't need to change this.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-29" class="outline-4">
<h4 id="sec-3-1-29">log.cleaner.backoff.ms</h4>
<div class="outline-text-4" id="text-3-1-29">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">15000</td>
</tr>
</tbody>
</table>
<p>
The interval between checks to see if any logs need cleaning.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-30" class="outline-4">
<h4 id="sec-3-1-30">log.cleaner.min.cleanable.ratio</h4>
<div class="outline-text-4" id="text-3-1-30">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">0.5</td>
</tr>
</tbody>
</table>
<p>
This configuration controls how frequently the log compactor will attempt to clean the log (assuming log compaction is enabled). By default we will avoid cleaning a log where more than 50% of the log has been compacted. This ratio bounds the maximum space wasted in the log by duplicates (at 50% at most 50% of the log could be duplicates). A higher ratio will mean fewer, more efficient cleanings but will mean more wasted space in the log. This setting can be overridden on a per-topic basis (see the per-topic configuration section).
</p>
</div>
</div>
<div id="outline-container-sec-3-1-31" class="outline-4">
<h4 id="sec-3-1-31">log.cleaner.delete.retention.ms</h4>
<div class="outline-text-4" id="text-3-1-31">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">1 day</td>
</tr>
</tbody>
</table>
<p>
The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan). This setting can be overridden on a per-topic basis (see the per-topic configuration section).
</p>
</div>
</div>
<div id="outline-container-sec-3-1-32" class="outline-4">
<h4 id="sec-3-1-32">log.index.size.max.bytes</h4>
<div class="outline-text-4" id="text-3-1-32">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">10 * 1024 * 1024</td>
</tr>
</tbody>
</table>
<p>
The maximum size in bytes we allow for the offset index for each log segment. Note that we will always pre-allocate a sparse file with this much space and shrink it down when the log rolls. If the index fills up we will roll a new log segment even if we haven't reached the log.segment.bytes limit. This setting can be overridden on a per-topic basis (see the per-topic configuration section).
</p>
</div>
</div>
<div id="outline-container-sec-3-1-33" class="outline-4">
<h4 id="sec-3-1-33">log.index.interval.bytes</h4>
<div class="outline-text-4" id="text-3-1-33">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">4096</td>
</tr>
</tbody>
</table>
<p>
The byte interval at which we add an entry to the offset index. When executing a fetch request the server must do a linear scan for up to this many bytes to find the correct position in the log to begin and end the fetch. So setting this value to be larger will mean larger index files (and a bit more memory usage) but less scanning. However the server will never add more than one index entry per log append (even if more than log.index.interval worth of messages are appended). In general you probably don't need to mess with this value.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-34" class="outline-4">
<h4 id="sec-3-1-34">log.flush.interval.messages</h4>
<div class="outline-text-4" id="text-3-1-34">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">Long.MaxValue</td>
</tr>
</tbody>
</table>
<p>
The number of messages written to a log partition before we force an fsync on the log. Setting this lower will sync data to disk more often but will have a major impact on performance. We generally recommend that people make use of replication for durability rather than depending on single-server fsync, however this setting can be used to be extra certain.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-35" class="outline-4">
<h4 id="sec-3-1-35">log.flush.scheduler.interval.ms</h4>
<div class="outline-text-4" id="text-3-1-35">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">Long.MaxValue</td>
</tr>
</tbody>
</table>
<p>
The frequency in ms that the log flusher checks whether any log is eligible to be flushed to disk.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-36" class="outline-4">
<h4 id="sec-3-1-36">log.flush.interval.ms</h4>
<div class="outline-text-4" id="text-3-1-36">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">Long.MaxValue</td>
</tr>
</tbody>
</table>
<p>
The maximum time between fsync calls on the log. If used in conjuction with log.flush.interval.messages the log will be flushed when either criteria is met.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-37" class="outline-4">
<h4 id="sec-3-1-37">log.delete.delay.ms</h4>
<div class="outline-text-4" id="text-3-1-37">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">60000</td>
</tr>
</tbody>
</table>
<p>
The period of time we hold log files around after they are removed from the in-memory segment index. This period of time allows any in-progress reads to complete uninterrupted without locking. You generally don't need to change this.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-38" class="outline-4">
<h4 id="sec-3-1-38">log.flush.offset.checkpoint.interval.ms</h4>
<div class="outline-text-4" id="text-3-1-38">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">60000</td>
</tr>
</tbody>
</table>
<p>
The frequency with which we checkpoint the last flush point for logs for recovery. You should not need to change this.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-39" class="outline-4">
<h4 id="sec-3-1-39">log.segment.delete.delay.ms</h4>
<div class="outline-text-4" id="text-3-1-39">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">60000</td>
</tr>
</tbody>
</table>
<p>
the amount of time to wait before deleting a file from the filesystem.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-40" class="outline-4">
<h4 id="sec-3-1-40">auto.create.topics.enable</h4>
<div class="outline-text-4" id="text-3-1-40">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">true</td>
</tr>
</tbody>
</table>
<p>
Enable auto creation of topic on the server. If this is set to true then attempts to produce data or fetch metadata for a non-existent topic will automatically create it with the default replication factor and number of partitions.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-41" class="outline-4">
<h4 id="sec-3-1-41">controller.socket.timeout.ms</h4>
<div class="outline-text-4" id="text-3-1-41">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">30000</td>
</tr>
</tbody>
</table>
<p>
The socket timeout for commands from the partition management controller to the replicas.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-42" class="outline-4">
<h4 id="sec-3-1-42">controller.message.queue.size</h4>
<div class="outline-text-4" id="text-3-1-42">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">Int.MaxValue</td>
</tr>
</tbody>
</table>
<p>
The buffer size for controller-to-broker-channels
</p>
</div>
</div>
<div id="outline-container-sec-3-1-43" class="outline-4">
<h4 id="sec-3-1-43">default.replication.factor</h4>
<div class="outline-text-4" id="text-3-1-43">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">1</td>
</tr>
</tbody>
</table>
<p>
The default replication factor for automatically created topics.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-44" class="outline-4">
<h4 id="sec-3-1-44">replica.lag.time.max.ms</h4>
<div class="outline-text-4" id="text-3-1-44">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">10000</td>
</tr>
</tbody>
</table>
<p>
If a follower hasn't sent any fetch requests for this window of time, the leader will remove the follower from ISR (in-sync replicas) and treat it as dead.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-45" class="outline-4">
<h4 id="sec-3-1-45">replica.lag.max.messages</h4>
<div class="outline-text-4" id="text-3-1-45">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">4000</td>
</tr>
</tbody>
</table>
<p>
If a replica falls more than this many messages behind the leader, the leader will remove the follower from ISR and treat it as dead.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-46" class="outline-4">
<h4 id="sec-3-1-46">replica.socket.timeout.ms</h4>
<div class="outline-text-4" id="text-3-1-46">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">30 * 1000</td>
</tr>
</tbody>
</table>
<p>
The socket timeout for network requests to the leader for replicating data.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-47" class="outline-4">
<h4 id="sec-3-1-47">replica.socket.receive.buffer.bytes</h4>
<div class="outline-text-4" id="text-3-1-47">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">64 * 1024</td>
</tr>
</tbody>
</table>
<p>
The socket receive buffer for network requests to the leader for replicating data.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-48" class="outline-4">
<h4 id="sec-3-1-48">replica.fetch.max.bytes</h4>
<div class="outline-text-4" id="text-3-1-48">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">1024 * 1024</td>
</tr>
</tbody>
</table>
<p>
The number of byes of messages to attempt to fetch for each partition in the fetch requests the replicas send to the leader.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-49" class="outline-4">
<h4 id="sec-3-1-49">replica.fetch.wait.max.ms</h4>
<div class="outline-text-4" id="text-3-1-49">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">500</td>
</tr>
</tbody>
</table>
<p>
The maximum amount of time to wait time for data to arrive on the leader in the fetch requests sent by the replicas to the leader.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-50" class="outline-4">
<h4 id="sec-3-1-50">replica.fetch.min.bytes</h4>
<div class="outline-text-4" id="text-3-1-50">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">1</td>
</tr>
</tbody>
</table>
<p>
Minimum bytes expected for each fetch response for the fetch requests from the replica to the leader. If not enough bytes, wait up to replica.fetch.wait.max.ms for this many bytes to arrive.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-51" class="outline-4">
<h4 id="sec-3-1-51">num.replica.fetchers</h4>
<div class="outline-text-4" id="text-3-1-51">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">1</td>
</tr>
</tbody>
</table>
<p>
Number of threads used to replicate messages from leaders. Increasing this value can increase the degree of I/O parallelism in the follower broker.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-52" class="outline-4">
<h4 id="sec-3-1-52">replica.high.watermark.checkpoint.interval.ms</h4>
<div class="outline-text-4" id="text-3-1-52">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">5000</td>
</tr>
</tbody>
</table>
<p>
The frequency with which each replica saves its high watermark to disk to handle recovery.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-53" class="outline-4">
<h4 id="sec-3-1-53">fetch.purgatory.purge.interval.requests</h4>
<div class="outline-text-4" id="text-3-1-53">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">1000</td>
</tr>
</tbody>
</table>
<p>
The purge interval (in number of requests) of the fetch request purgatory.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-54" class="outline-4">
<h4 id="sec-3-1-54">producer.purgatory.purge.interval.requests</h4>
<div class="outline-text-4" id="text-3-1-54">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">1000</td>
</tr>
</tbody>
</table>
<p>
The purge interval (in number of requests) of the producer request purgatory.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-55" class="outline-4">
<h4 id="sec-3-1-55">zookeeper.session.timeout.ms</h4>
<div class="outline-text-4" id="text-3-1-55">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">6000</td>
</tr>
</tbody>
</table>
<p>
ZooKeeper session timeout. If the server fails to heartbeat to ZooKeeper within this period of time it is considered dead. If you set this too low the server may be falsely considered dead; if you set it too high it may take too long to recognize a truly dead server.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-56" class="outline-4">
<h4 id="sec-3-1-56">zookeeper.connection.timeout.ms</h4>
<div class="outline-text-4" id="text-3-1-56">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">6000</td>
</tr>
</tbody>
</table>
<p>
The maximum amount of time that the client waits to establish a connection to zookeeper.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-57" class="outline-4">
<h4 id="sec-3-1-57">zookeeper.sync.time.ms</h4>
<div class="outline-text-4" id="text-3-1-57">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">2000</td>
</tr>
</tbody>
</table>
<p>
How far a ZK follower can be behind a ZK leader.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-58" class="outline-4">
<h4 id="sec-3-1-58">controlled.shutdown.enable</h4>
<div class="outline-text-4" id="text-3-1-58">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">true</td>
</tr>
</tbody>
</table>
<p>
Enable controlled shutdown of the broker. If enabled, the broker will move all leaders on it to some other brokers before shutting itself down. This reduces the unavailability window during shutdown.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-59" class="outline-4">
<h4 id="sec-3-1-59">controlled.shutdown.max.retries</h4>
<div class="outline-text-4" id="text-3-1-59">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">3</td>
</tr>
</tbody>
</table>
<p>
Number of retries to complete the controlled shutdown successfully before executing an unclean shutdown.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-60" class="outline-4">
<h4 id="sec-3-1-60">controlled.shutdown.retry.backoff.ms</h4>
<div class="outline-text-4" id="text-3-1-60">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">5000</td>
</tr>
</tbody>
</table>
<p>
Backoff time between shutdown retries.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-61" class="outline-4">
<h4 id="sec-3-1-61">auto.leader.rebalance.enable</h4>
<div class="outline-text-4" id="text-3-1-61">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">true</td>
</tr>
</tbody>
</table>
<p>
If this is enabled the controller will automatically try to balance leadership for partitions among the brokers by periodically returning leadership to the "preferred" replica for each partition if it is available.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-62" class="outline-4">
<h4 id="sec-3-1-62">leader.imbalance.per.broker.percentage</h4>
<div class="outline-text-4" id="text-3-1-62">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">10</td>
</tr>
</tbody>
</table>
<p>
The percentage of leader imbalance allowed per broker. The controller will rebalance leadership if this ratio goes above the configured value per broker.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-63" class="outline-4">
<h4 id="sec-3-1-63">leader.imbalance.check.interval.seconds</h4>
<div class="outline-text-4" id="text-3-1-63">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">300</td>
</tr>
</tbody>
</table>
<p>
The frequency with which to check for leader imbalance.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-64" class="outline-4">
<h4 id="sec-3-1-64">offset.metadata.max.bytes</h4>
<div class="outline-text-4" id="text-3-1-64">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">4096</td>
</tr>
</tbody>
</table>
<p>
The maximum amount of metadata to allow clients to save with their offsets.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-65" class="outline-4">
<h4 id="sec-3-1-65">max.connections.per.ip</h4>
<div class="outline-text-4" id="text-3-1-65">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">Int.MaxValue</td>
</tr>
</tbody>
</table>
<p>
The maximum number of connections that a broker allows from each ip address.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-66" class="outline-4">
<h4 id="sec-3-1-66">max.connections.per.ip.overrides</h4>
<div class="outline-text-4" id="text-3-1-66">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">&#xa0;</td>
</tr>
</tbody>
</table>
<p>
Per-ip or hostname overrides to the default maximum number of connections.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-67" class="outline-4">
<h4 id="sec-3-1-67">connections.max.idle.ms</h4>
<div class="outline-text-4" id="text-3-1-67">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">600000</td>
</tr>
</tbody>
</table>
<p>
Idle connections timeout: the server socket processor threads close the connections that idle more than this.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-68" class="outline-4">
<h4 id="sec-3-1-68">log.roll.jitter.{ms,hours}</h4>
<div class="outline-text-4" id="text-3-1-68">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">0</td>
</tr>
</tbody>
</table>
<p>
The maximum jitter to subtract from logRollTimeMillis.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-69" class="outline-4">
<h4 id="sec-3-1-69">num.recovery.threads.per.data.dir</h4>
<div class="outline-text-4" id="text-3-1-69">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">1</td>
</tr>
</tbody>
</table>
<p>
The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-70" class="outline-4">
<h4 id="sec-3-1-70">unclean.leader.election.enable</h4>
<div class="outline-text-4" id="text-3-1-70">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">true</td>
</tr>
</tbody>
</table>
<p>
Indicates whether to enable replicas not in the ISR set to be elected as leader as a last resort, even though doing so may result in data loss.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-71" class="outline-4">
<h4 id="sec-3-1-71">delete.topic.enable</h4>
<div class="outline-text-4" id="text-3-1-71">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="left">false</td>
</tr>
</tbody>
</table>
<p>
Enable delete topic.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-72" class="outline-4">
<h4 id="sec-3-1-72">offsets.topic.num.partitions</h4>
<div class="outline-text-4" id="text-3-1-72">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">50</td>
</tr>
</tbody>
</table>
<p>
The number of partitions for the offset commit topic. Since changing this after deployment is currently unsupported, we recommend using a higher setting for production (e.g., 100-200).
</p>
</div>
</div>
<div id="outline-container-sec-3-1-73" class="outline-4">
<h4 id="sec-3-1-73">offsets.topic.retention.minutes</h4>
<div class="outline-text-4" id="text-3-1-73">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">1440</td>
</tr>
</tbody>
</table>
<p>
Offsets that are older than this age will be marked for deletion. The actual purge will occur when the log cleaner compacts the offsets topic.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-74" class="outline-4">
<h4 id="sec-3-1-74">offsets.retention.check.interval.ms</h4>
<div class="outline-text-4" id="text-3-1-74">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">600000</td>
</tr>
</tbody>
</table>
<p>
The frequency at which the offset manager checks for stale offsets.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-75" class="outline-4">
<h4 id="sec-3-1-75">offsets.topic.replication.factor</h4>
<div class="outline-text-4" id="text-3-1-75">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">3</td>
</tr>
</tbody>
</table>
<p>
The replication factor for the offset commit topic. A higher setting (e.g., three or four) is recommended in order to ensure higher availability. If the offsets topic is created when fewer brokers than the replication factor then the offsets topic will be created with fewer replicas.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-76" class="outline-4">
<h4 id="sec-3-1-76">offsets.topic.segment.bytes</h4>
<div class="outline-text-4" id="text-3-1-76">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">104857600</td>
</tr>
</tbody>
</table>
<p>
Segment size for the offsets topic. Since it uses a compacted topic, this should be kept relatively low in order to facilitate faster log compaction and loads.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-77" class="outline-4">
<h4 id="sec-3-1-77">offsets.load.buffer.size</h4>
<div class="outline-text-4" id="text-3-1-77">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">5242880</td>
</tr>
</tbody>
</table>
<p>
An offset load occurs when a broker becomes the offset manager for a set of consumer groups (i.e., when it becomes a leader for an offsets topic partition). This setting corresponds to the batch size (in bytes) to use when reading from the offsets segments when loading offsets into the offset manager's cache.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-78" class="outline-4">
<h4 id="sec-3-1-78">offsets.commit.required.acks</h4>
<div class="outline-text-4" id="text-3-1-78">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">-1</td>
</tr>
</tbody>
</table>
<p>
The number of acknowledgements that are required before the offset commit can be accepted. This is similar to the producer's acknowledgement setting. In general, the default should not be overridden.
</p>
</div>
</div>
<div id="outline-container-sec-3-1-79" class="outline-4">
<h4 id="sec-3-1-79">offsets.commit.timeout.ms</h4>
<div class="outline-text-4" id="text-3-1-79">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">デフォルト</td>
<td class="right">5000</td>
</tr>
</tbody>
</table>
<p>
The offset commit will be delayed until this timeout or the required number of replicas have received the offset commit. This is similar to the producer request timeout.
</p>
</div>
</div>

<div id="outline-container-topic-config" class="outline-4">
<h4 id="topic-config"><a id="sec-3-1-80" name="sec-3-1-80"></a>Topic-level configuration</h4>
<div class="outline-text-4" id="text-topic-config">

<p>
Configurations pertinent to topics have both a global default as well an optional per-topic override.
If no per-topic configuration is given the global default is used.
The override can be set at topic creation time by giving one or more <code>--config</code> options.
This example creates a topic named <i>my-topic</i> with a custom max message size and flush rate:
</p>

<pre class="example">
&gt; bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic my-topic --partitions 1
       --replication-factor 1 --config max.message.bytes=64000 --config flush.messages=1
</pre>

<p>
Overrides can also be changed or set later using the alter topic command. This example updates the max message size for <i>my-topic</i>:
</p>

<pre class="example">
&gt; bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic my-topic
   --config max.message.bytes=128000
</pre>

<p>
To remove an override you can do
</p>

<pre class="example">
&gt; bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic my-topic
   --deleteConfig max.message.bytes
</pre>


<p>
The following are the topic-level configurations. The server's default configuration for this property is given under the Server Default Property heading, setting this default in the server config allows you to change the default given to topics that have no override specified.
</p>
</div>


<ul class="org-ul"><li><a id="sec-3-1-80-1" name="sec-3-1-80-1"></a>cleanup.policy<br  /><div class="outline-text-5" id="text-3-1-80-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">delete</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="left">log.cleanup.policy</td>
</tr>
</tbody>
</table>
<p>
A string that is either "delete" or "compact". This string designates the retention policy to use on old log segments. The default policy ("delete") will discard old segments when their retention time or size limit has been reached. The "compact" setting will enable log compaction on the topic.
</p>
</div>
</li>
<li><a id="sec-3-1-80-2" name="sec-3-1-80-2"></a>delete.retention.ms<br  /><div class="outline-text-5" id="text-3-1-80-2">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">86400000 (24 hours)</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="left">log.cleaner.delete.retention.ms</td>
</tr>
</tbody>
</table>
<p>
The amount of time to retain delete tombstone markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan).
</p>
</div>
</li>
<li><a id="sec-3-1-80-3" name="sec-3-1-80-3"></a>flush.messages<br  /><div class="outline-text-5" id="text-3-1-80-3">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">None</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="left">log.flush.interval.messages</td>
</tr>
</tbody>
</table>
<p>
This setting allows specifying an interval at which we will force an fsync of data written to the log. For example if this was set to 1 we would fsync after every message; if it were 5 we would fsync after every five messages. In general we recommend you not set this and use replication for durability and allow the operating system's background flush capabilities as it is more efficient. This setting can be overridden on a per-topic basis (see the per-topic configuration section).
</p>
</div>
</li>
<li><a id="sec-3-1-80-4" name="sec-3-1-80-4"></a>flush.ms<br  /><div class="outline-text-5" id="text-3-1-80-4">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">None</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="left">log.flush.interval.ms</td>
</tr>
</tbody>
</table>
<p>
This setting allows specifying a time interval at which we will force an fsync of data written to the log. For example if this was set to 1000 we would fsync after 1000 ms had passed. In general we recommend you not set this and use replication for durability and allow the operating system's background flush capabilities as it is more efficient.
</p>
</div>
</li>
<li><a id="sec-3-1-80-5" name="sec-3-1-80-5"></a>index.interval.bytes<br  /><div class="outline-text-5" id="text-3-1-80-5">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">4096</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="right">log.index.interval.bytes</td>
</tr>
</tbody>
</table>
<p>
This setting controls how frequently Kafka adds an index entry to it's offset index. The default setting ensures that we index a message roughly every 4096 bytes. More indexing allows reads to jump closer to the exact position in the log but makes the index larger. You probably don't need to change this.
</p>
</div>
</li>
<li><a id="sec-3-1-80-6" name="sec-3-1-80-6"></a>max.message.bytes<br  /><div class="outline-text-5" id="text-3-1-80-6">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">1,000,000</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="left">message.max.bytes</td>
</tr>
</tbody>
</table>
<p>
This is largest message size Kafka will allow to be appended to this topic. Note that if you increase this size you must also increase your consumer's fetch size so they can fetch messages this large.
</p>
</div>
</li>
<li><a id="sec-3-1-80-7" name="sec-3-1-80-7"></a>min.cleanable.dirty.ratio<br  /><div class="outline-text-5" id="text-3-1-80-7">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">0.5</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="right">log.cleaner.min.cleanable.ratio</td>
</tr>
</tbody>
</table>
<p>
This configuration controls how frequently the log compactor will attempt to clean the log (assuming log compaction is enabled). By default we will avoid cleaning a log where more than 50% of the log has been compacted. This ratio bounds the maximum space wasted in the log by duplicates (at 50% at most 50% of the log could be duplicates). A higher ratio will mean fewer, more efficient cleanings but will mean more wasted space in the log.
</p>
</div>
</li>
<li><a id="sec-3-1-80-8" name="sec-3-1-80-8"></a>min.insync.replicas<br  /><div class="outline-text-5" id="text-3-1-80-8">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">1</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="right">min.insync.replicas</td>
</tr>
</tbody>
</table>
<p>
When a producer sets request.required.acks to -1, min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend).
</p>

<p>
When used together, min.insync.replicas and request.required.acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with request.required.acks of -1. This will ensure that the producer raises an exception if a majority of replicas do not receive a write.
</p>
</div>
</li>
<li><a id="sec-3-1-80-9" name="sec-3-1-80-9"></a>retention.bytes<br  /><div class="outline-text-5" id="text-3-1-80-9">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">None</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="left">log.retention.bytes</td>
</tr>
</tbody>
</table>
<p>
This configuration controls the maximum size a log can grow to before we will discard old log segments to free up space if we are using the "delete" retention policy. By default there is no size limit only a time limit.
</p>
</div>
</li>
<li><a id="sec-3-1-80-10" name="sec-3-1-80-10"></a>retention.ms<br  /><div class="outline-text-5" id="text-3-1-80-10">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">7 days</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="left">log.retention.minutes</td>
</tr>
</tbody>
</table>
<p>
This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the "delete" retention policy. This represents an SLA on how soon consumers must read their data.
</p>
</div>
</li>
<li><a id="sec-3-1-80-11" name="sec-3-1-80-11"></a>segment.bytes<br  /><div class="outline-text-5" id="text-3-1-80-11">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">1 GB</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="left">log.segment.bytes</td>
</tr>
</tbody>
</table>
<p>
This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention.
</p>
</div>
</li>
<li><a id="sec-3-1-80-12" name="sec-3-1-80-12"></a>segment.index.bytes<br  /><div class="outline-text-5" id="text-3-1-80-12">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">10 MB</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="left">log.index.size.max.bytes</td>
</tr>
</tbody>
</table>
<p>
This configuration controls the size of the index that maps offsets to file positions. We preallocate this index file and shrink it only after log rolls. You generally should not need to change this setting.
</p>
</div>
</li>
<li><a id="sec-3-1-80-13" name="sec-3-1-80-13"></a>segment.ms<br  /><div class="outline-text-5" id="text-3-1-80-13">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">7 days</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="left">log.roll.hours</td>
</tr>
</tbody>
</table>
<p>
This configuration controls the period of time after which Kafka will force the log to roll even if the segment file isn't full to ensure that retention can delete or compact old data.
</p>
</div>
</li>
<li><a id="sec-3-1-80-14" name="sec-3-1-80-14"></a>segment.jitter.ms<br  /><div class="outline-text-5" id="text-3-1-80-14">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">0</td>
</tr>

<tr>
<td class="left">Server Default Property</td>
<td class="right">log.roll.jitter.{ms,hours}</td>
</tr>
</tbody>
</table>
<p>
The maximum jitter to subtract from logRollTimeMillis.
</p>
</div>
</li></ul>
</div>
</div>

<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2"><span class="section-number-3">3.2</span> Consumer Configs</h3>
<div class="outline-text-3" id="text-3-2">
<p>
The essential consumer configurations are the following:
</p>

<ul class="org-ul">
<li><code>group.id</code>
</li>
<li><code>zookeeper.connect</code>
</li>
</ul>

<p>
More details about consumer configuration can be found in the scala class <code>kafka.consumer.ConsumerConfig</code>.
</p>
</div>

<div id="outline-container-sec-3-2-1" class="outline-4">
<h4 id="sec-3-2-1">group.id</h4>
<div class="outline-text-4" id="text-3-2-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">&#xa0;</td>
</tr>
</tbody>
</table>
<p>
A string that uniquely identifies the group of consumer processes to which this consumer belongs. By setting the same group id multiple processes indicate that they are all part of the same consumer group.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-2" class="outline-4">
<h4 id="sec-3-2-2">zookeeper.connect</h4>
<div class="outline-text-4" id="text-3-2-2">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">&#xa0;</td>
</tr>
</tbody>
</table>
<p>
Specifies the ZooKeeper connection string in the form <code>hostname:port</code> where host and port are the host and port of a ZooKeeper server. To allow connecting through other ZooKeeper nodes when that ZooKeeper machine is down you can also specify multiple hosts in the form <code>hostname1:port1,hostname2:port2,hostname3:port3</code>. The server may also have a ZooKeeper chroot path as part of it's ZooKeeper connection string which puts its data under some path in the global ZooKeeper namespace. If so the consumer should use the same chroot path in its connection string. For example to give a chroot path of <code>/chroot/path</code> you would give the connection string as <code>hostname1:port1,hostname2:port2,hostname3:port3/chroot/path</code>.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-3" class="outline-4">
<h4 id="sec-3-2-3">consumer.id</h4>
<div class="outline-text-4" id="text-3-2-3">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">null</td>
</tr>
</tbody>
</table>
<p>
Generated automatically if not set.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-4" class="outline-4">
<h4 id="sec-3-2-4">socket.timeout.ms</h4>
<div class="outline-text-4" id="text-3-2-4">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">30 * 1000</td>
</tr>
</tbody>
</table>
<p>
The socket timeout for network requests. The actual timeout set will be max.fetch.wait + socket.timeout.ms.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-5" class="outline-4">
<h4 id="sec-3-2-5">socket.receive.buffer.bytes</h4>
<div class="outline-text-4" id="text-3-2-5">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">64 * 1024</td>
</tr>
</tbody>
</table>
<p>
The socket receive buffer for network requests
</p>
</div>
</div>
<div id="outline-container-sec-3-2-6" class="outline-4">
<h4 id="sec-3-2-6">fetch.message.max.bytes</h4>
<div class="outline-text-4" id="text-3-2-6">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">1024 * 1024</td>
</tr>
</tbody>
</table>
<p>
The number of byes of messages to attempt to fetch for each topic-partition in each fetch request. These bytes will be read into memory for each partition, so this helps control the memory used by the consumer. The fetch request size must be at least as large as the maximum message size the server allows or else it is possible for the producer to send messages larger than the consumer can fetch.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-7" class="outline-4">
<h4 id="sec-3-2-7">num.consumer.fetchers</h4>
<div class="outline-text-4" id="text-3-2-7">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">1</td>
</tr>
</tbody>
</table>
<p>
The number fetcher threads used to fetch data.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-8" class="outline-4">
<h4 id="sec-3-2-8">auto.commit.enable</h4>
<div class="outline-text-4" id="text-3-2-8">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">true</td>
</tr>
</tbody>
</table>
<p>
If true, periodically commit to ZooKeeper the offset of messages already fetched by the consumer. This committed offset will be used when the process fails as the position from which the new consumer will begin.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-9" class="outline-4">
<h4 id="sec-3-2-9">auto.commit.interval.ms</h4>
<div class="outline-text-4" id="text-3-2-9">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">60 * 1000</td>
</tr>
</tbody>
</table>
<p>
The frequency in ms that the consumer offsets are committed to zookeeper.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-10" class="outline-4">
<h4 id="sec-3-2-10">queued.max.message.chunks</h4>
<div class="outline-text-4" id="text-3-2-10">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">2</td>
</tr>
</tbody>
</table>
<p>
Max number of message chunks buffered for consumption. Each chunk can be up to fetch.message.max.bytes.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-11" class="outline-4">
<h4 id="sec-3-2-11">rebalance.max.retries</h4>
<div class="outline-text-4" id="text-3-2-11">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">4</td>
</tr>
</tbody>
</table>
<p>
When a new consumer joins a consumer group the set of consumers attempt to "rebalance" the load to assign partitions to each consumer. If the set of consumers changes while this assignment is taking place the rebalance will fail and retry. This setting controls the maximum number of attempts before giving up.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-12" class="outline-4">
<h4 id="sec-3-2-12">fetch.min.bytes</h4>
<div class="outline-text-4" id="text-3-2-12">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">1</td>
</tr>
</tbody>
</table>
<p>
The minimum amount of data the server should return for a fetch request. If insufficient data is available the request will wait for that much data to accumulate before answering the request.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-13" class="outline-4">
<h4 id="sec-3-2-13">fetch.wait.max.ms</h4>
<div class="outline-text-4" id="text-3-2-13">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">100</td>
</tr>
</tbody>
</table>
<p>
The maximum amount of time the server will block before answering the fetch request if there isn't sufficient data to immediately satisfy fetch.min.bytes
</p>
</div>
</div>
<div id="outline-container-sec-3-2-14" class="outline-4">
<h4 id="sec-3-2-14">rebalance.backoff.ms</h4>
<div class="outline-text-4" id="text-3-2-14">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">2000</td>
</tr>
</tbody>
</table>
<p>
Backoff time between retries during rebalance.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-15" class="outline-4">
<h4 id="sec-3-2-15">refresh.leader.backoff.ms</h4>
<div class="outline-text-4" id="text-3-2-15">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">200</td>
</tr>
</tbody>
</table>
<p>
Backoff time to wait before trying to determine the leader of a partition that has just lost its leader.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-16" class="outline-4">
<h4 id="sec-3-2-16">auto.offset.reset</h4>
<div class="outline-text-4" id="text-3-2-16">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">largest</td>
</tr>
</tbody>
</table>
<p>
What to do when there is no initial offset in ZooKeeper or if an offset is out of range:
</p>

<dl class="org-dl">
<dt> smallest </dt><dd>automatically reset the offset to the smallest offset
</dd>
<dt> largest </dt><dd>automatically reset the offset to the largest offset
</dd>
<dt> anything else </dt><dd>throw exception to the consumer
</dd>
</dl>
</div>
</div>

<div id="outline-container-sec-3-2-17" class="outline-4">
<h4 id="sec-3-2-17">consumer.timeout.ms</h4>
<div class="outline-text-4" id="text-3-2-17">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">-1</td>
</tr>
</tbody>
</table>
<p>
Throw a timeout exception to the consumer if no message is available for consumption after the specified interval
</p>
</div>
</div>
<div id="outline-container-sec-3-2-18" class="outline-4">
<h4 id="sec-3-2-18">exclude.internal.topics</h4>
<div class="outline-text-4" id="text-3-2-18">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">true</td>
</tr>
</tbody>
</table>
<p>
Whether messages from internal topics (such as offsets) should be exposed to the consumer.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-19" class="outline-4">
<h4 id="sec-3-2-19">partition.assignment.strategy</h4>
<div class="outline-text-4" id="text-3-2-19">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">range</td>
</tr>
</tbody>
</table>
<p>
Select a strategy for assigning partitions to consumer streams. Possible values: range, roundrobin.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-20" class="outline-4">
<h4 id="sec-3-2-20">client.id</h4>
<div class="outline-text-4" id="text-3-2-20">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">group id value</td>
</tr>
</tbody>
</table>
<p>
The client id is a user-specified string sent in each request to help trace calls. It should logically identify the application making the request.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-21" class="outline-4">
<h4 id="sec-3-2-21">zookeeper.session.timeout.ms</h4>
<div class="outline-text-4" id="text-3-2-21">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">6000</td>
</tr>
</tbody>
</table>
<p>
ZooKeeper session timeout. If the consumer fails to heartbeat to ZooKeeper for this period of time it is considered dead and a rebalance will occur.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-22" class="outline-4">
<h4 id="sec-3-2-22">zookeeper.connection.timeout.ms</h4>
<div class="outline-text-4" id="text-3-2-22">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">6000</td>
</tr>
</tbody>
</table>
<p>
The max time that the client waits while establishing a connection to zookeeper.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-23" class="outline-4">
<h4 id="sec-3-2-23">zookeeper.sync.time.ms</h4>
<div class="outline-text-4" id="text-3-2-23">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">2000</td>
</tr>
</tbody>
</table>
<p>
How far a ZK follower can be behind a ZK leader
</p>
</div>
</div>
<div id="outline-container-sec-3-2-24" class="outline-4">
<h4 id="sec-3-2-24">offsets.storage</h4>
<div class="outline-text-4" id="text-3-2-24">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">zookeeper</td>
</tr>
</tbody>
</table>
<p>
Select where offsets should be stored (zookeeper or kafka).
</p>
</div>
</div>
<div id="outline-container-sec-3-2-25" class="outline-4">
<h4 id="sec-3-2-25">offsets.channel.backoff.ms</h4>
<div class="outline-text-4" id="text-3-2-25">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">1000</td>
</tr>
</tbody>
</table>
<p>
The backoff period when reconnecting the offsets channel or retrying failed offset fetch/commit requests.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-26" class="outline-4">
<h4 id="sec-3-2-26">offsets.channel.socket.timeout.ms</h4>
<div class="outline-text-4" id="text-3-2-26">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">10000</td>
</tr>
</tbody>
</table>
<p>
Socket timeout when reading responses for offset fetch/commit requests. This timeout is also used for ConsumerMetadata requests that are used to query for the offset manager.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-27" class="outline-4">
<h4 id="sec-3-2-27">offsets.commit.max.retries</h4>
<div class="outline-text-4" id="text-3-2-27">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">5</td>
</tr>
</tbody>
</table>
<p>
Retry the offset commit up to this many times on failure. This retry count only applies to offset commits during shut-down. It does not apply to commits originating from the auto-commit thread. It also does not apply to attempts to query for the offset coordinator before committing offsets. i.e., if a consumer metadata request fails for any reason, it will be retried and that retry does not count toward this limit.
</p>
</div>
</div>
<div id="outline-container-sec-3-2-28" class="outline-4">
<h4 id="sec-3-2-28">dual.commit.enabled</h4>
<div class="outline-text-4" id="text-3-2-28">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">true</td>
</tr>
</tbody>
</table>
<p>
If you are using "kafka" as offsets.storage, you can dual commit offsets to ZooKeeper (in addition to Kafka). This is required during migration from zookeeper-based offset storage to kafka-based offset storage. With respect to any given consumer group, it is safe to turn this off after all instances within that group have been migrated to the new version that commits offsets to the broker (instead of directly to ZooKeeper).
</p>
</div>
</div>
<div id="outline-container-sec-3-2-29" class="outline-4">
<h4 id="sec-3-2-29">partition.assignment.strategy</h4>
<div class="outline-text-4" id="text-3-2-29">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">range</td>
</tr>
</tbody>
</table>
<p>
Select between the "range" or "roundrobin" strategy for assigning partitions to consumer streams.
</p>

<p>
The round-robin partition assignor lays out all the available partitions and all the available consumer threads. It then proceeds to do a round-robin assignment from partition to consumer thread. If the subscriptions of all consumer instances are identical, then the partitions will be uniformly distributed. (i.e., the partition ownership counts will be within a delta of exactly one across all consumer threads.) Round-robin assignment is permitted only if: (a) Every topic has the same number of streams within a consumer instance (b) The set of subscribed topics is identical for every consumer instance within the group.
</p>

<p>
Range partitioning works on a per-topic basis. For each topic, we lay out the available partitions in numeric order and the consumer threads in lexicographic order. We then divide the number of partitions by the total number of consumer streams (threads) to determine the number of partitions to assign to each consumer. If it does not evenly divide, then the first few consumers will have one extra partition.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3-3" class="outline-3">
<h3 id="sec-3-3"><span class="section-number-3">3.3</span> Producer Configs</h3>
<div class="outline-text-3" id="text-3-3">
<p>
Essential configuration properties for the producer include:
</p>

<ul class="org-ul">
<li><code>metadata.broker.list</code>
</li>
<li><code>request.required.acks</code>
</li>
<li><code>producer.type</code>
</li>
<li><code>serializer.class</code>
</li>
</ul>

<p>
More details about producer configuration can be found in the scala class <code>kafka.producer.ProducerConfig</code>.
</p>
</div>

<div id="outline-container-sec-3-3-1" class="outline-4">
<h4 id="sec-3-3-1">metadata.broker.list</h4>
<div class="outline-text-4" id="text-3-3-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">&#xa0;</td>
</tr>
</tbody>
</table>
<p>
This is for bootstrapping and the producer will only use it for getting metadata (topics, partitions and replicas). The socket connections for sending the actual data will be established based on the broker information returned in the metadata. The format is <code>host1:port1,host2:port2</code>, and the list can be a subset of brokers or a VIP pointing to a subset of brokers.
</p>
</div>
</div>

<div id="outline-container-sec-3-3-2" class="outline-4">
<h4 id="sec-3-3-2">request.required.acks</h4>
<div class="outline-text-4" id="text-3-3-2">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">0</td>
</tr>
</tbody>
</table>
<p>
This value controls when a produce request is considered completed. Specifically, how many other brokers must have committed the data to their log and acknowledged this to the leader? Typical values are
</p>

<ul class="org-ul">
<li>0, which means that the producer never waits for an acknowledgement from the broker (the same behavior as 0.7).
This option provides the lowest latency but the weakest durability guarantees (some data will be lost when a server fails).
</li>
<li>1, which means that the producer gets an acknowledgement after the leader replica has received the data. 
This option provides better durability as the client waits until the server acknowledges the request as successful (only messages that were written to the now-dead leader but not yet replicated will be lost).
</li>
<li>-1, The producer gets an acknowledgement after all in-sync replicas have received the data.
This option provides the greatest level of durability.
However, it does not completely eliminate the risk of message loss because the number of in sync replicas may, in rare cases, shrink to 1.
If you want to ensure that some minimum number of replicas (typically a majority) receive a write, then you must set the topic-level min.insync.replicas setting.
Please read the Replication section of the design documentation for a more in-depth discussion.
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-3-3-3" class="outline-4">
<h4 id="sec-3-3-3">request.timeout.ms</h4>
<div class="outline-text-4" id="text-3-3-3">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">10000</td>
</tr>
</tbody>
</table>
<p>
The amount of time the broker will wait trying to meet the request.required.acks requirement before sending back an error to the client.
</p>
</div>
</div>
<div id="outline-container-sec-3-3-4" class="outline-4">
<h4 id="sec-3-3-4">producer.type</h4>
<div class="outline-text-4" id="text-3-3-4">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">sync</td>
</tr>
</tbody>
</table>
<p>
This parameter specifies whether the messages are sent asynchronously in a background thread. Valid values are (1) async for asynchronous send and (2) sync for synchronous send. By setting the producer to async we allow batching together of requests (which is great for throughput) but open the possibility of a failure of the client machine dropping unsent data.
</p>
</div>
</div>
<div id="outline-container-sec-3-3-5" class="outline-4">
<h4 id="sec-3-3-5">serializer.class</h4>
<div class="outline-text-4" id="text-3-3-5">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">kafka.serializer.DefaultEncoder</td>
</tr>
</tbody>
</table>
<p>
The serializer class for messages. The default encoder takes a byte[] and returns the same byte[].
</p>
</div>
</div>
<div id="outline-container-sec-3-3-6" class="outline-4">
<h4 id="sec-3-3-6">key.serializer.class</h4>
<div class="outline-text-4" id="text-3-3-6">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">&#xa0;</td>
</tr>
</tbody>
</table>
<p>
The serializer class for keys (defaults to the same as for messages if nothing is given).
</p>
</div>
</div>
<div id="outline-container-sec-3-3-7" class="outline-4">
<h4 id="sec-3-3-7">partitioner.class</h4>
<div class="outline-text-4" id="text-3-3-7">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">kafka.producer.DefaultPartitioner</td>
</tr>
</tbody>
</table>
<p>
The partitioner class for partitioning messages amongst sub-topics. The default partitioner is based on the hash of the key.
</p>
</div>
</div>
<div id="outline-container-sec-3-3-8" class="outline-4">
<h4 id="sec-3-3-8">compression.codec</h4>
<div class="outline-text-4" id="text-3-3-8">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">none</td>
</tr>
</tbody>
</table>
<p>
This parameter allows you to specify the compression codec for all data generated by this producer. Valid values are "none", "gzip" and "snappy".
</p>
</div>
</div>
<div id="outline-container-sec-3-3-9" class="outline-4">
<h4 id="sec-3-3-9">compressed.topics</h4>
<div class="outline-text-4" id="text-3-3-9">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">null</td>
</tr>
</tbody>
</table>
<p>
This parameter allows you to set whether compression should be turned on for particular topics. If the compression codec is anything other than NoCompressionCodec, enable compression only for specified topics if any. If the list of compressed topics is empty, then enable the specified compression codec for all topics. If the compression codec is NoCompressionCodec, compression is disabled for all topics
</p>
</div>
</div>
<div id="outline-container-sec-3-3-10" class="outline-4">
<h4 id="sec-3-3-10">message.send.max.retries</h4>
<div class="outline-text-4" id="text-3-3-10">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">3</td>
</tr>
</tbody>
</table>
<p>
This property will cause the producer to automatically retry a failed send request. This property specifies the number of retries when such failures occur. Note that setting a non-zero value here can lead to duplicates in the case of network errors that cause a message to be sent but the acknowledgement to be lost.
</p>
</div>
</div>
<div id="outline-container-sec-3-3-11" class="outline-4">
<h4 id="sec-3-3-11">retry.backoff.ms</h4>
<div class="outline-text-4" id="text-3-3-11">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">100</td>
</tr>
</tbody>
</table>
<p>
Before each retry, the producer refreshes the metadata of relevant topics to see if a new leader has been elected. Since leader election takes a bit of time, this property specifies the amount of time that the producer waits before refreshing the metadata.
</p>
</div>
</div>
<div id="outline-container-sec-3-3-12" class="outline-4">
<h4 id="sec-3-3-12">topic.metadata.refresh.interval.ms</h4>
<div class="outline-text-4" id="text-3-3-12">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">600 * 1000</td>
</tr>
</tbody>
</table>
<p>
The producer generally refreshes the topic metadata from brokers when there is a failure (partition missing, leader not available&#x2026;). It will also poll regularly (default: every 10min so 600000ms). If you set this to a negative value, metadata will only get refreshed on failure. If you set this to zero, the metadata will get refreshed after each message sent (not recommended). Important note: the refresh happen only AFTER the message is sent, so if the producer never sends a message the metadata is never refreshed
</p>
</div>
</div>
<div id="outline-container-sec-3-3-13" class="outline-4">
<h4 id="sec-3-3-13">queue.buffering.max.ms</h4>
<div class="outline-text-4" id="text-3-3-13">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">5000</td>
</tr>
</tbody>
</table>
<p>
Maximum time to buffer data when using async mode. For example a setting of 100 will try to batch together 100ms of messages to send at once. This will improve throughput but adds message delivery latency due to the buffering.
</p>
</div>
</div>
<div id="outline-container-sec-3-3-14" class="outline-4">
<h4 id="sec-3-3-14">queue.buffering.max.messages</h4>
<div class="outline-text-4" id="text-3-3-14">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">10000</td>
</tr>
</tbody>
</table>
<p>
The maximum number of unsent messages that can be queued up the producer when using async mode before either the producer must be blocked or data must be dropped.
</p>
</div>
</div>
<div id="outline-container-sec-3-3-15" class="outline-4">
<h4 id="sec-3-3-15">queue.enqueue.timeout.ms</h4>
<div class="outline-text-4" id="text-3-3-15">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">-1</td>
</tr>
</tbody>
</table>
<p>
The amount of time to block before dropping messages when running in async mode and the buffer has reached queue.buffering.max.messages. If set to 0 events will be enqueued immediately or dropped if the queue is full (the producer send call will never block). If set to -1 the producer will block indefinitely and never willingly drop a send.
</p>
</div>
</div>
<div id="outline-container-sec-3-3-16" class="outline-4">
<h4 id="sec-3-3-16">batch.num.messages</h4>
<div class="outline-text-4" id="text-3-3-16">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="right" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="right">200</td>
</tr>
</tbody>
</table>
<p>
The number of messages to send in one batch when using async mode. The producer will wait until either this number of messages are ready to send or queue.buffer.max.ms is reached.
</p>
</div>
</div>
<div id="outline-container-sec-3-3-17" class="outline-4">
<h4 id="sec-3-3-17">send.buffer.bytes</h4>
<div class="outline-text-4" id="text-3-3-17">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">100 * 1024</td>
</tr>
</tbody>
</table>
<p>
Socket write buffer size
</p>
</div>
</div>
<div id="outline-container-sec-3-3-18" class="outline-4">
<h4 id="sec-3-3-18">client.id</h4>
<div class="outline-text-4" id="text-3-3-18">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Default</td>
<td class="left">""</td>
</tr>
</tbody>
</table>
<p>
The client id is a user-specified string sent in each request to help trace calls. It should logically identify the application making the request.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3-4" class="outline-3">
<h3 id="sec-3-4"><span class="section-number-3">3.4</span> New Producer Configs</h3>
<div class="outline-text-3" id="text-3-4">
<p>
We are working on a replacement for our existing producer. The code is available in trunk now and can be considered beta quality. Below is the configuration for the new producer. 
</p>
</div>

<div id="outline-container-sec-3-4-1" class="outline-4">
<h4 id="sec-3-4-1">bootstrap.servers</h4>
<div class="outline-text-4" id="text-3-4-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">list</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">&#xa0;</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">high</td>
</tr>
</tbody>
</table>
<p>
A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. Data will be load balanced over all servers irrespective of which servers are specified here for bootstrapping—this list only impacts the initial hosts used to discover the full set of servers. This list should be in the form <code>host1:port1,host2:port2</code>,&#x2026;. Since these servers are just used for the initial connection to discover the full cluster membership (which may change dynamically), this list need not contain the full set of servers (you may want more than one, though, in case a server is down). If no server in this list is available sending data will fail until on becomes available.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-2" class="outline-4">
<h4 id="sec-3-4-2">acks</h4>
<div class="outline-text-4" id="text-3-4-2">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">string</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">1</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">high</td>
</tr>
</tbody>
</table>
<p>
The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the durability of records that are sent. The following settings are common:
</p>

<ul class="org-ul">
<li><code>acks=0</code> If set to zero then the producer will not wait for any acknowledgment from the server at all. The record will be immediately added to the socket buffer and considered sent. No guarantee can be made that the server has received the record in this case, and the <code>retries</code> configuration will not take effect (as the client won't generally know of any failures). The offset given back for each record will always be set to -1.
</li>
<li><code>acks=1</code> This will mean the leader will write the record to its local log but will respond without awaiting full acknowledgement from all followers. In this case should the leader fail immediately after acknowledging the record but before the followers have replicated it then the record will be lost.
</li>
<li><code>acks=all</code> This means the leader will wait for the full set of in-sync replicas to acknowledge the record. This guarantees that the record will not be lost as long as at least one in-sync replica remains alive. This is the strongest available guarantee.
</li>
<li>Other settings such as <code>acks=2</code> are also possible, and will require the given number of acknowledgements but this is generally less useful.
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-3-4-3" class="outline-4">
<h4 id="sec-3-4-3">buffer.memory</h4>
<div class="outline-text-4" id="text-3-4-3">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">long</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">33554432</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">high</td>
</tr>
</tbody>
</table>
<p>
The total bytes of memory the producer can use to buffer records waiting to be sent to the server. If records are sent faster than they can be delivered to the server the producer will either block or throw an exception based on the preference specified by <code>block.on.buffer.full</code>.
</p>

<p>
This setting should correspond roughly to the total memory the producer will use, but is not a hard bound since not all memory the producer uses is used for buffering. Some additional memory will be used for compression (if compression is enabled) as well as for maintaining in-flight requests.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-4" class="outline-4">
<h4 id="sec-3-4-4">compression.type</h4>
<div class="outline-text-4" id="text-3-4-4">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">string</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">none</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">high</td>
</tr>
</tbody>
</table>
<p>
The compression type for all data generated by the producer. The default is none (i.e. no compression). Valid values are <code>none</code>, <code>gzip</code>, or <code>snappy</code>. Compression is of full batches of data, so the efficacy of batching will also impact the compression ratio (more batching means better compression).
</p>
</div>
</div>
<div id="outline-container-sec-3-4-5" class="outline-4">
<h4 id="sec-3-4-5">retries</h4>
<div class="outline-text-4" id="text-3-4-5">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">int</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">0</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">high</td>
</tr>
</tbody>
</table>
<p>
Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially transient error. Note that this retry is no different than if the client resent the record upon receiving the error. Allowing retries will potentially change the ordering of records because if two records are sent to a single partition, and the first fails and is retried but the second succeeds, then the second record may appear first.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-6" class="outline-4">
<h4 id="sec-3-4-6">batch.size</h4>
<div class="outline-text-4" id="text-3-4-6">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">int</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">16384</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">medium</td>
</tr>
</tbody>
</table>
<p>
The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition. This helps performance on both the client and the server. This configuration controls the default batch size in bytes.
</p>

<p>
No attempt will be made to batch records larger than this size.
</p>

<p>
Requests sent to brokers will contain multiple batches, one for each partition with data available to be sent.
</p>

<p>
A small batch size will make batching less common and may reduce throughput (a batch size of zero will disable batching entirely). A very large batch size may use memory a bit more wastefully as we will always allocate a buffer of the specified batch size in anticipation of additional records.
</p>
</div>
</div>

<div id="outline-container-sec-3-4-7" class="outline-4">
<h4 id="sec-3-4-7">client.id</h4>
<div class="outline-text-4" id="text-3-4-7">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">string</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">&#xa0;</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">medium</td>
</tr>
</tbody>
</table>
<p>
The id string to pass to the server when making requests. The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a logical application name to be included with the request. The application can set any string it wants as this has no functional purpose other than in logging and metrics.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-8" class="outline-4">
<h4 id="sec-3-4-8">linger.ms</h4>
<div class="outline-text-4" id="text-3-4-8">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">long</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">0</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">medium</td>
</tr>
</tbody>
</table>
<p>
The producer groups together any records that arrive in between request transmissions into a single batched request. Normally this occurs only under load when records arrive faster than they can be sent out. However in some circumstances the client may want to reduce the number of requests even under moderate load. This setting accomplishes this by adding a small amount of artificial delay—that is, rather than immediately sending out a record the producer will wait for up to the given delay to allow other records to be sent so that the sends can be batched together. This can be thought of as analogous to Nagle's algorithm in TCP. This setting gives the upper bound on the delay for batching: once we get <code>batch.size</code> worth of records for a partition it will be sent immediately regardless of this setting, however if we have fewer than this many bytes accumulated for this partition we will 'linger' for the specified time waiting for more records to show up. This setting defaults to 0 (i.e. no delay). Setting <code>linger.ms=5</code>, for example, would have the effect of reducing the number of requests sent but would add up to 5ms of latency to records sent in the absense of load.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-9" class="outline-4">
<h4 id="sec-3-4-9">max.request.size</h4>
<div class="outline-text-4" id="text-3-4-9">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">int</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">1048576</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">medium</td>
</tr>
</tbody>
</table>
<p>
The maximum size of a request. This is also effectively a cap on the maximum record size. Note that the server has its own cap on record size which may be different from this. This setting will limit the number of record batches the producer will send in a single request to avoid sending huge requests.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-10" class="outline-4">
<h4 id="sec-3-4-10">receive.buffer.bytes</h4>
<div class="outline-text-4" id="text-3-4-10">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">int</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">32768</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">medium</td>
</tr>
</tbody>
</table>
<p>
The size of the TCP receive buffer to use when reading data
</p>
</div>
</div>
<div id="outline-container-sec-3-4-11" class="outline-4">
<h4 id="sec-3-4-11">send.buffer.bytes</h4>
<div class="outline-text-4" id="text-3-4-11">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">int</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">131072</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">medium</td>
</tr>
</tbody>
</table>
<p>
The size of the TCP send buffer to use when sending data
</p>
</div>
</div>
<div id="outline-container-sec-3-4-12" class="outline-4">
<h4 id="sec-3-4-12">timeout.ms</h4>
<div class="outline-text-4" id="text-3-4-12">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">int</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">30000</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">medium</td>
</tr>
</tbody>
</table>
<p>
The configuration controls the maximum amount of time the server will wait for acknowledgments from followers to meet the acknowledgment requirements the producer has specified with the <code>acks</code> configuration. If the requested number of acknowledgments are not met when the timeout elapses an error will be returned. This timeout is measured on the server side and does not include the network latency of the request.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-13" class="outline-4">
<h4 id="sec-3-4-13">block.on.buffer.full</h4>
<div class="outline-text-4" id="text-3-4-13">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">boolean</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">true</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">low</td>
</tr>
</tbody>
</table>
<p>
When our memory buffer is exhausted we must either stop accepting new records (block) or throw errors. By default this setting is true and we block, however in some scenarios blocking is not desirable and it is better to immediately give an error. Setting this to <code>false</code> will accomplish that: the producer will throw a BufferExhaustedException if a recrord is sent and the buffer space is full.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-14" class="outline-4">
<h4 id="sec-3-4-14">metadata.fetch.timeout.ms</h4>
<div class="outline-text-4" id="text-3-4-14">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">long</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">60000</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">low</td>
</tr>
</tbody>
</table>
<p>
The first time data is sent to a topic we must fetch metadata about that topic to know which servers host the topic's partitions. This configuration controls the maximum amount of time we will block waiting for the metadata fetch to succeed before throwing an exception back to the client.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-15" class="outline-4">
<h4 id="sec-3-4-15">metadata.max.age.ms</h4>
<div class="outline-text-4" id="text-3-4-15">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">long</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">300000</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">low</td>
</tr>
</tbody>
</table>
<p>
The period of time in milliseconds after which we force a refresh of metadata even if we haven't seen any partition leadership changes to proactively discover any new brokers or partitions.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-16" class="outline-4">
<h4 id="sec-3-4-16">metric.reporters</h4>
<div class="outline-text-4" id="text-3-4-16">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">list</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">[]</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">low</td>
</tr>
</tbody>
</table>
<p>
A list of classes to use as metrics reporters. Implementing the <code>MetricReporter</code> interface allows plugging in classes that will be notified of new metric creation. The JmxReporter is always included to register JMX statistics.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-17" class="outline-4">
<h4 id="sec-3-4-17">metrics.num.samples</h4>
<div class="outline-text-4" id="text-3-4-17">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">int</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">2</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">low</td>
</tr>
</tbody>
</table>
<p>
The number of samples maintained to compute metrics.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-18" class="outline-4">
<h4 id="sec-3-4-18">metrics.sample.window.ms</h4>
<div class="outline-text-4" id="text-3-4-18">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">long</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">30000</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">low</td>
</tr>
</tbody>
</table>
<p>
The metrics system maintains a configurable number of samples over a fixed window size. This configuration controls the size of the window. For example we might maintain two samples each measured over a 30 second period. When a window expires we erase and overwrite the oldest window.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-19" class="outline-4">
<h4 id="sec-3-4-19">reconnect.backoff.ms</h4>
<div class="outline-text-4" id="text-3-4-19">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">long</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">10</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">low</td>
</tr>
</tbody>
</table>
<p>
The amount of time to wait before attempting to reconnect to a given host when a connection fails. This avoids a scenario where the client repeatedly attempts to connect to a host in a tight loop.
</p>
</div>
</div>
<div id="outline-container-sec-3-4-20" class="outline-4">
<h4 id="sec-3-4-20">retry.backoff.ms</h4>
<div class="outline-text-4" id="text-3-4-20">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">Type</td>
<td class="left">long</td>
</tr>

<tr>
<td class="left">Default</td>
<td class="left">100</td>
</tr>

<tr>
<td class="left">Importance</td>
<td class="left">low</td>
</tr>
</tbody>
</table>
<p>
The amount of time to wait before attempting to retry a failed produce request to a given topic partition. This avoids repeated sending-and-failing in a tight loop.
</p>
</div>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" name="fn.1" class="footnum" href="#fnr.1">1</a></sup> <p>(訳注) 警告は無視してよさそうです。 <a href="https://issues.apache.org/jira/browse/KAFKA-1711">0.8.3で修正される見込みのようです</a> 。</p></div>

<div class="footdef"><sup><a id="fn.2" name="fn.2" class="footnum" href="#fnr.2">2</a></sup> <p>(訳注) 0.8.2 のリリースにconsumerも一部既に含まれていますが、正式には 0.9 で利用可能なようです( <a href="http://mail-archives.apache.org/mod_mbox/kafka-users/201505.mbox/<7D2658D6A1CA594AAD4246FFB16B38786FED5F7A@LCA1-MB04.linkedin.biz>">RE: Java Consumer API</a> 、 <a href="http://mail-archives.apache.org/mod_mbox/kafka-users/201503.mbox/<D13F868B.15C38%25jqin@linkedin.com>">Re: Consumer in Java client</a> )</p></div>

<div class="footdef"><sup><a id="fn.3" name="fn.3" class="footnum" href="#fnr.3">3</a></sup> <p>(訳注) 関連ソース <a href="https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/consumer/ConsumerConnector.scala">ConsumerConnector</a> 、<a href="https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/consumer/KafkaStream.scala">KafkaStream</a> 、 <a href="https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/message/MessageAndMetadata.scala">MessageAndMetadata</a></p></div>

<div class="footdef"><sup><a id="fn.4" name="fn.4" class="footnum" href="#fnr.4">4</a></sup> <p>(訳注) 関連ソース <a href="https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/consumer/SimpleConsumer.scala">SimpleConsumer</a> 、 <a href="https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/api/FetchRequest.scala">FetchRequest</a> 、 <a href="https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/api/FetchResponse.scala">FetchResponse</a> 、 <a href="https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/api/TopicMetadataRequest.scala">TopicMetadataRequest</a> 、 <a href="https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/api/TopicMetadataResponse.scala">TopicMetadataResponse</a> 、<a href="https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/api/OffsetRequest.scala">OffsetRequest</a> 、<a href="https://github.com/apache/kafka/blob/0.8.2/core/src/main/scala/kafka/api/OffsetResponse.scala">OffsetResponse</a></p></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: yewton</p>
<p class="date">Created: 2015-05-18 月 22:02</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.4.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
