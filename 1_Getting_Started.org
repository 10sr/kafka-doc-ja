#+STARTUP: content

** 導入

Kafka は分散し、分割され、複製されるコミットログサービスです。
メッセージングシステムの機能を提供しますが、その設計は独特なものです。

つまり、どういうことでしょう？

はじめに、基本的なメッセージングの用語を確認しておきましょう:

- Kafka は /トピック/ と呼ばれるカテゴリ毎にメッセージのフィードを保持しています
- Kafka のトピックに対してメッセージを発行するプロセスを /プロデューサ/ と呼びます
- 複数のトピックを購読し、発行されたメッセージのフィードを処理するプロセスを /コンシューマ/ と呼びます
- Kafka はひとつ以上の /ブローカ/ と呼ばれるサーバで構成されるクラスタとして動作します

すなわち以下の図のように、高レベルな視点ではプロデューサ群がネットワーク上で Kafka クラスタにメッセージを送信し、
そのメッセージを順次コンシューマ群に向けて提供する、というように動作します:

[[file:images/producer_consumer.png]]

クライアントとサーバ間の通信はシンプルかつ高性能で、言語に依存しない [[https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol][TCP protocol]] で行なわれます。
提供されるのは Java の Kafka クライアントですが、 [[https://cwiki.apache.org/confluence/display/KAFKA/Clients][多くの言語で]] 利用することが出来ます。

*** トピックとログ

まず最初に、 Kafka が提供する高レベルな抽象概念である「トピック」について見ていきましょう。

トピックはカテゴリ、あるいはフィードの名前であり、メッセージはトピックに対して発行されます。
以下の図のように、Kafka クラスタはトピックごとにログを分割して保持しています:

[[file:images/log_anatomy.png]]

各パーティションは不変で順序があるメッセージ列で、メッセージは断続的に追記されます。
このメッセージ列を「コミットログ」と呼びます。
メッセージには、格納されたパーティションごとに「オフセット」と呼ばれるユニークな通し番号が付与されます。
このオフセットにより、パーティション内のメッセージを一意に特定することができます。

Kafka クラスタは、コンシュームされたかどうかに拘わらず、発行されたすべてのメッセージを保存しています。
保持する期間は設定で変更可能です。
例えばログ保存期間が2日間に設定されている場合、あるメッセージが発行されてから2日間はコンシューム可能ですが、
それ以降は容量確保のために破棄されます。
Kafkaの性能はデータサイズに関しては実質定数のため、大量のデータを保存することは問題ありません。

実は、コンシューマ毎に保存されているメタデータというのは、ログ内のコンシューマの位置情報だけです。
これは「オフセット」と呼ばれます。
オフセットはコンシューマにより制御されます————通常はメッセージを読み進めるのに応じて順番にオフセットを進めますが、
オフセットの制御は実際のところコンシューマが行なうため、任意の順序でコンシュームすることが出来ます。
例えば、コンシューマは昔のオフセットにリセットして再処理を行なうことが出来ます。

以上の機能の組合せにより、Kafkaのコンシューマはとても安価であると言えます————コンシューマはクラスタへの参加・離脱を、
そのクラスタや、クラスタに所属する他のコンシューマに大きな影響を与えることなく行なうことができる、ということです。
例えば、任意のトピックについて、付属のコマンドラインツールで「tail」操作を行なうことが出来ますが、
これは既存のコンシューマのコンシューム状況を変えることなく行なうことが可能です。

パーティションは様々な目的で提供されています。
第一に、ログを一台のサーバに収まりきらないサイズにまでスケールすることを可能にする目的です。
個々のパーティションについては、それを格納するサーバに収まるように調整する必要がありますが、
トピックは複数のパーティションに分割されるため、トピックのデータ量は無制限です。
第二に、パーティションは並行処理の単位としても利用されます————詳細は後述します。

*** 分散

ログのパーティションは Kafka クラスタ内のサーバ上で分散して保持されており、
各サーバはパーティションを共有するためのデータとリクエストを処理します。
耐障害性のために、各パーティションを複数のサーバに複製することも出来ます。
複製するサーバ数は設定で変更可能です。

各パーティションは「リーダ」となる一つのサーバと、0以上の「フォロワ」サーバを持ちます。
リーダは担当のパーティションへの全ての読み書きリクエストを処理します。
対してフォロワは、リーダの複製を受動的に行ないます。
リーダに障害が発生した場合、フォロワのどれかが自動的に新たなリーダとなります。
各サーバはクラスタ内の負荷が均等になるように、自身のパーティションのうちいくつかのリーダとなり、
その他のパーティションのフォロワともなります。

*** プロデューサ

プロデューサは自身の選択したトピックに対してデータを発行します。
プロデューサはどのメッセージをトピック内のどのパーティションに割り当てるかを選択する責務があります。
これは負荷分散のためにラウンドロビン方式で選択することも出来ますし、
何らかの意味的な分割関数を利用することも出来ます(例えばメッセージの特定のキーを元に分割するなど)。
パーティションの利用に関する詳細は後述します。

*** コンシューマ

伝統的なメッセージングのモデルは [[http://en.wikipedia.org/wiki/Message_queue][キューイング]] と [[http://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern][出版・購読型]] の二つです。
キューを用いる方法では、コンシューマプールがひとつのサーバからメッセージを取得することができ、
各メッセージはコンシューマのいずれか一つに渡ります。
一方の出版・購読型モデルでは、メッセージは全てのコンシューマにブロードキャストされます。
Kafka はその両方を一般化するコンシューマの抽象概念を提供しています。
それが「コンシューマグループ」です。

コンシューマは自分自身にコンシューマグループ名をラベル付けしており、
トピックに発行される各メッセージは、そのトピックを購読している各コンシューマグループそれぞれの、
ある一つのコンシューマインスタンスに対して屆けられます。
コンシューマインスタンスは異なるプロセス、あるいは異なるサーバ上で稼動させることが出来ます。

全てのコンシューマインスタンスが同一のコンシューマグループに属しているならば、
コンシューマ上で負荷分散される伝統的なキューイングモデルのように動きます。

全てのコンシューマインスタンスがそれぞれ異なるコンシューマグループに属しているならば、
出版・購読型モデルのように動き、メッセージは全てのコンシューマにブロードキャストされることになります。

しかしより一般には、トピックは「論理的な購読者」を表す少数のコンシューマグループを持つことになるでしょう。
各グループはスケーラビリティと耐障害性のため、複数のコンシューマインスタンスで構成されます。
これは購読者が単一のプロセスではなく、コンシューマのクラスタとなっている出版・購読型モデルそのものです。

#+CAPTION: 4つのパーティション(P0-P3)をホスティングする2つのサーバで構成されるKafka クラスタ、及び2つのコンシューマグループ。グループAは2つ、Bは4つのインスタンスを持っている。
[[file:images/consumer-groups.png]]

また、Kafkaは伝統的なメッセージングシステムと比べてより強力な順序保証を提供しています。

伝統的なキューはメッセージを順番にサーバ上に保存しています。
複数のコンシューマがそのキューからコンシュームした場合、
サーバは保存されている順番にメッセージを取り出すでしょう。
しかし、サーバがメッセージを順番に取り出したところで、
コンシューマへのメッセージの配信は非同期に行われるため、
異なるコンシューマ間のメッセージ到達順序は狂う可能性があります。
つまり、コンシューマを並列に動かすような状況では、メッセージの順序は失われる、ということです。
メッセージングシステムはしばしば「排他的コンシューマ」という概念を利用して問題を回避しようとします。
ひとつのキューに対してただひとつプロセスのみコンシューム可能とする、というものです。
しかしこれは当然、並列処理は出来ません。

Kafka はもっと上手いことやっています。
トピック内の並列性(これはつまり、パーティションのことです)という概念を利用することで、
Kafkaはコンシューマプロセスプール上の順序保証と負荷分散の両方を提供することが出来ます。
これは、各パーティションがグループ内のただ一つのコンシューマにのみコンシュームされるように、
トピック内のパーティションをコンシューマグループ内のコンシューマに割り当てることで実現されています。
これによって、パーティションを読むのはある特定コンシューマだけであることと、順序通りコンシュームすることが保証されます。
多くのパーティションがある為、これでもコンシューマインスタンス間の負荷は分散します。
ただし、パーティション数以上のコンシューマインスタンスは存在し得ないことに注意してください。

Kafka はトピック内のパーティションの /中の/ メッセージ順序しか保証しません。
異なるパーティション間の順序は保証されません。
ほとんどのアプリケーションは、パーティション毎の順序とキー毎の分割機能との組み合わせで十分でしょう。
もし、全メッセージの順序が必要な場合は、パーティションひとつだけからなるトピックを使うことで実現出来ますが、
この場合コンシューマプロセスもただ一つのみになります。

*** 保証

高レベルな視点では Kafka は以下の保証を提供します:

- プロデューサから特定のトピックパーティションへと送られたメッセージは、送られた順に追記されます。
  つまり、メッセージ =M1= と =M2= が同じプロデューサから送られ、かつ =M1= が最初に送られていた場合、
  =M1= は =M2= よりも小さいオフセットを持ち、 =M2= よりも先にログに現れます。
- コンシューマインスタンスはログに保存されている順番にメッセージを読みます。
- レプリケーションファクタ =N= に設定されたトピックは、 =N-1= 個までのサーバ障害については、
  メッセージのロスト無く稼動することが出来ます。

これらの保証のより詳細については、本ドキュメントの設計セクションで述べられています。

** ユースケース

Apache Kafka のユースケースをいくつか紹介します。
これらの分野についての数多くの取り組みの概要が [[http://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying][このブログ記事]] にまとめられています。

*** メッセージング

Kafka は伝統的なメッセージブローカの代替として使うことが出来ます。
メッセージブローカを利用する理由は様々です————
データ生成と処理を疎結合にする為、未処理のメッセージをバッファするため、等。
ほとんどのメッセージングシステムと比較して、
Kafka はより良いスループット、組込みのパーティショニング、複製、耐障害性を備えており、
大規模メッセージ処理アプリケーションの良いソリューションとなります。

経験上、メッセージングは比較的低いスループットで、しかしエンドツーエンドの低いレイテンシを要求し、
また、Kafka が提供する強い堅牢性に関する保証に依存するという場合が多いです。

このドメインでは、 [[http://activemq.apache.org/][ActiveMQ]] や [[http://activemq.apache.org/][ActiveMQ]] のような伝統的なメッセージングシステムと Kafka を比較することが出来ます。

*** Web サイトのアクティビティトラッキング

ユーザ動向追跡パイプラインを、リアルタイムな Pub-Sub フィードの集合として再構築する、というのが Kafka の元々のユースケースでした。
つまり、サイトアクティビティ(ページビュー、検索等のユーザが取り得る行動)はアクティビティの種別毎にトピック分けされて、
中央に集められるということです。
これらのフィードは幅広いユースケースで利用することが出来ます。
リアルタイム処理やリアルタイム監視のために使われたり、
オフラインでの処理やレポートで利用するために Hadoop やオフラインのデータウェアハウジングシステムへ保存するために使われたりします。

アクティビティトラッキングは各ユーザのページビューごとに大量のアクティビティメッセージが生成されるため、
しばしば超大容量のログを扱うことになります。

*** メトリクス

Kafka は運用監視データとしても使われることがあります。
この場合は、運用データの中央フィードを生成するため、分散したアプリケーションの統計を集約するのに用いられます。

*** ログ集約

ログ集約ソリューションの代替として Kafka を利用する場合も多いです。
典型的なログ集約では、物理ログファイルをサーバから収集し、
ファイルサーバや HDFS のような中央ストレージに配置して処理されます。
Kafka はファイルの詳細について抽象化し、
また、ログやイベントデータをメッセージストリームとしてきれいに抽象化しています。
これにより、より低レイテンシで処理でき、また複数のデータソースや分散データ処理への対応が容易になります。
Scribe や Flume といったログ集約システムと比較して、
Kafka や同等のパフォーマンスと、複製によるより強い堅牢性保証、
及びエンドツーエンドのより低いレイテンシを提供します。


*** ストリーム処理

多くのユーザは段階的なデータ処理をすることになります。
データは生データのトピックからコンシュームされ、集約され、肉付けされ、
あるいはさらなるコンシュームの為に新たな Kafka トピックへの変換されます。
例えば記事レコメンドの処理フローは次のようなものになるでしょう:
まず、RSS フィードから記事をクロールし、「記事」トピックに発行します。
続いて、内容を正規化したり重複を除いて、「クリーンな記事内容」トピックに発行します。
最後に、記事内容とユーザのマッチングを行ないます。
このような処理のフローは、個々のトピックから始まるリアルタイムデータフローのグラフを形成します。
[[https://storm.apache.org/][Storm]] や [[http://samza.apache.org/][Samza]] はこのような類の変換を行なうための有名なフレームワークです。

*** イベントソーシング

[[http://martinfowler.com/eaaDev/EventSourcing.html][イベントソーシング]] はアプリケーション設計手法のひとつで、
状態の変更が時系列順のレコード列として記録されるというものです。
Kafka は超巨大なログデータを扱えるため、
この手法で構築されたアプリケーションの優れたバックエンドとして利用することが出来ます。

*** コミットログ

Kafka を分散システムのための外部コミットログとして使うこともできます。
ノード間でデータを複製したり、障害ノードの復旧のための再同期機構として、このログを利用することが出来ます。
Kafka の [[http://kafka.apache.org/documentation.html#compaction][ログコンパクション]] 機能もこの用途に適しています。
この用途では、Kafka と [[http://zookeeper.apache.org/bookkeeper/][Apache BookKeeper]] プロジェクトは似ています。

** クイックスタート

このチュートリアルは、まっさらな環境で、KafkaやZooKeeperが一切稼動していない前提で進めます。

*** ステップ 1: コードのダウンロード

0.8.2.0 リリースを [[https://www.apache.org/dyn/closer.cgi?path%3D/kafka/0.8.2.0/kafka_2.10-0.8.2.0.tgz][ダウンロード]] して、解凍しましょう。

#+BEGIN_SRC
> tar -xzf kafka_2.10-0.8.2.0.tgz
> cd kafka_2.10-0.8.2.0
#+END_SRC

*** ステップ 2: サーバの起動

Kafka は ZooKeeper を使うため、まずは ZooKeeper サーバを起動する必要があります。
既に起動している ZooKeeper サーバがある場合は、新たに起動する必要はありません。
新たに起動する場合は、 Kafka に同梱されている便利スクリプトを使ってください。
このスクリプトは、単一ノードを手早く作るための適当なものです。

#+BEGIN_SRC
> bin/zookeeper-server-start.sh config/zookeeper.properties
[2013-04-22 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...
#+END_SRC

では、 Kafka サーバを起動しましょう:

#+BEGIN_SRC
> bin/kafka-server-start.sh config/server.properties
[2013-04-22 15:01:47,028] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2013-04-22 15:01:47,051] INFO Property socket.send.buffer.bytes is overridden to 1048576 (kafka.utils.VerifiableProperties)
...
#+END_SRC

*** ステップ 3: トピックの作成

今度は「test」という名前の、単一パーティションで、複製を作らないトピックを作成してみましょう:

#+BEGIN_SRC
> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
#+END_SRC

list コマンドで、作成したトピックを参照できるようになるはずです:

#+BEGIN_SRC
> bin/kafka-topics.sh --list --zookeeper localhost:2181
test
#+END_SRC

また、手動でトピックを作成するのではなく、存在しないトピックへパブリッシュされた場合に自動で作成するようにブローカを設定することもできます。

*** ステップ 4: メッセージを送ってみる

Kafka にはファイルか標準入力から Kafka クラスタにメッセージを送信出来るコマンドラインのクライアントが同梱されています。
デフォルトでは、各行がそれぞれ異なるメッセージとして送信されます。

プロデューサスクリプトを起動し、コンソールにメッセージを打ちこんでサーバに送信してみましょう。

#+BEGIN_SRC
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
[2015-05-15 19:45:39,512] WARN Property topic is not valid (kafka.utils.VerifiableProperties)
これはメッセージです
これは別のメッセージです
^D
#+END_SRC

(訳注) 警告は無視してよさそうです。 [[https://issues.apache.org/jira/browse/KAFKA-1711][0.8.3で修正される見込みのようです]] 。


*** ステップ 5: コンシューマを起動する

Kafka にはメッセージを標準出力にダンプするコマンドラインのコンシューマも付属しています。

#+BEGIN_SRC
> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
これはメッセージです
これも別のメッセージです
^CConsumed 2 messages
#+END_SRC

別々のターミナルで上記の両方のコマンドを実行すれば、プロデューサのターミナルでメッセージを打ち込むと、
コンシューマのターミナルでそれを確認することが出来ます。

全てのコマンドラインツールには追加のオプションがあります。
引数なしでコマンドを実行すると、より詳細が参照出来る使い方のドキュメントが出力されます。

*** ステップ 6: マルチブローカクラスタを立ち上げる

ここまでは、単一のブローカ上で動作させて決ましたが、これではあまり面白くないですね。
単一のブローカというのは Kafka にとってはサイズ1のクラスタに過ぎないので、
複数のブローカインスタンスを起動することもそれほど違いはありません。
ですが、感覚を掴む為に3ノードのクラスタに拡張してみましょう(とはいえ、まだ全てのノードは同じローカルマシン上です)。

まず、各ブローカ用の設定ファイルを作ります:

#+BEGIN_SRC
> cp config/server.properties config/server-1.properties
> cp config/server.properties config/server-2.properties
#+END_SRC

続いて、これらのファイルを編集して、以下のプロパティを設定します:

#+BEGIN_SRC
config/server-1.properties:
    broker.id=1
    port=9093
    log.dirs=/tmp/kafka-logs-1
#+END_SRC

#+BEGIN_SRC
config/server-2.properties:
    broker.id=2
    port=9094
    log.dirs=/tmp/kafka-logs-2
#+END_SRC

=broker.id= は、各ノードのクラスタ内でユニークな、永続的な名前を表すプロパティです。
ポート番号とログディレクトリだけは変更が必要です。
いま、これらのブローカは全て同一のマシン上で稼動しているので、
同じポート番号に登録しようとしたり、お互いのデータを上書きしあったりしてしまわないようにする必要があるためです。

既に ZooKeeper と単一ノードは起動しているので、3ノードのクラスタにするには、新しく2つのノードを立ち上げるだけです:

#+BEGIN_SRC
> bin/kafka-server-start.sh config/server-1.properties > /dev/null 2>&1 &
...
> bin/kafka-server-start.sh config/server-2.properties > /dev/null 2>&1 &
...
#+END_SRC

では、レプリケーションファクタ3のトピックを作成してみます:

#+BEGIN_SRC
> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
#+END_SRC

出来ました、が、クラスタ上のブローカの状態を見るにはどうすればよいのでしょう？
その為には "describe topics" コマンドを実行します:

#+BEGIN_SRC
> bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 1	Replicas: 1,2,0	Isr: 1,2,0
#+END_SRC

出力内容の説明をします。
最初の行が全パーティションの要約で、続く各行がそれぞれ1パーティションの情報を表します。
このトピックにはパーティションが一つしかないので、出力は1行しかありません。

- =Leader= はそのパーティションの全読み書きの責務を負うノードです。各ノードは、ランダムに選択されたパーティションのリーダになり得ます
- =Replicas= はこのパーティションのログを複製しているノードのリストです。リーダか否か、現在生存しているノードかどうかにはかかわらず表示されます
- =Isr= は「同期中」の複製を表します。 =Replicas= のリストのうち、現在生存しており、リーダに追い付いているノードが表示されます

この例では、ノード1はこのトピックの唯一のパーティションのリーダであることに着目してください。

同じコマンドを最初に作ったトピックについて実行して、ブローカの状況を見てみましょう:

#+BEGIN_SRC
> bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test
Topic:test	PartitionCount:1	ReplicationFactor:1	Configs:
	Topic: test	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
#+END_SRC

特に変わったところはありません——このトピックは複製を一切持たず、元々クラスタを作成したときの唯一のノードである server 0 上にあります。

さて、新しく作った方のトピックにいくつかメッセージをパブリッシュしてみましょう:

#+BEGIN_SRC
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic
...
my test message 1
my test message 2
^D
#+END_SRC

続いてこれらのメッセージをコンシュームします:

#+BEGIN_SRC
> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic
...
my test message 1
my test message 2
^C
#+END_SRC

ここで、耐障害性のテストをしてみましょう。
今はブローカ1がリーダなので、こいつを殺しましょう:

#+BEGIN_SRC
> ps | grep server-1.properties
7564 ttys002    0:15.91 /System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home/bin/java...
> kill -9 7564
#+END_SRC

リーダシップがスレーブノードの1つに移され、ノード1は =Isr= から外れます:

#+BEGIN_SRC
> bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 2	Replicas: 1,2,0	Isr: 2,0
#+END_SRC

元々の書き込みを引き受けたリーダがダウンしているにもかかわらず、なおメッセージはコンシューム可能です。

#+BEGIN_SRC
> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic
...
my test message 1
my test message 2
^C
#+END_SRC

** Ecosystem
There are a plethora of tools that integrate with Kafka outside the main distribution. The [[https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem][ecosystem page]] lists many of these, including stream processing systems, Hadoop integration, monitoring, and deployment tools.

** Upgrading From Previous Versions

*** Upgrading from 0.8.1 to 0.8.2.0
0.8.2.0 is fully compatible with 0.8.1. The upgrade can be done one broker at a time by simply bringing it down, updating the code, and restarting it.

*** Upgrading from 0.8.0 to 0.8.1
0.8.1 is fully compatible with 0.8. The upgrade can be done one broker at a time by simply bringing it down, updating the code, and restarting it.

*** Upgrading from 0.7
0.8, the release in which added replication, was our first backwards-incompatible release: major changes were made to the API, ZooKeeper data structures, and protocol, and configuration. The upgrade from 0.7 to 0.8.x requires a [[https://cwiki.apache.org/confluence/display/KAFKA/Migrating+from+0.7+to+0.8][special tool]] for migration. This migration can be done without downtime.

# Local Variables:
# org-export-allow-bind-keywords: t
# End:
